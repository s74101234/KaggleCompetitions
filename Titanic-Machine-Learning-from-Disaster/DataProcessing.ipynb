{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Replace Type to Number {Female, Male} = {0, 1}\n",
    "def ReplaceTypeToNum(data):\n",
    "    print('Class：', data.unique())\n",
    "    classLE = LabelEncoder()\n",
    "    data = classLE.fit_transform(data.values)\n",
    "    return data\n",
    "\n",
    "# Select Feature\n",
    "def SelectFeature(data, data2):\n",
    "    PassengerId = data['PassengerId']\n",
    "    Survived = data['Survived']\n",
    "    y = data['Survived'].values\n",
    "    x = data.drop(columns=['PassengerId', 'Survived']).values\n",
    "    data = data.drop(columns=['PassengerId', 'Survived'])\n",
    "    \n",
    "    #using ExtraTreesClassifier(極限樹)\n",
    "    ETC = ExtraTreesClassifier(n_estimators = 500)\n",
    "    ETC = ETC.fit(x, y)\n",
    "    print('Feature Importances：', ETC.feature_importances_)\n",
    "    ETCModel = SelectFromModel(ETC, prefit = True)\n",
    "    \n",
    "    data = data.loc[:,ETCModel.get_support()]\n",
    "    data['PassengerId'] = PassengerId\n",
    "    col = []\n",
    "    for key in data2.columns:\n",
    "        if key in data.columns:\n",
    "            col.append(True)\n",
    "        else:\n",
    "            col.append(False)\n",
    "    data2 = data2.loc[:, col]\n",
    "    data['Survived'] = Survived\n",
    "    return data, data2\n",
    "\n",
    "# Compare Association Between Type\n",
    "def CompareAssBetType(data, keyword1, keyword2):\n",
    "#     print(pd.crosstab(dataMerge['NameTitle'], dataMerge['Sex']))\n",
    "    return data[[keyword1, keyword2]].groupby([keyword1], as_index=False).mean().sort_values(by=keyword2, ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Compare Association Between Type\n",
      "   Pclass  Survived\n",
      "1       2  0.800000\n",
      "0       1  0.670886\n",
      "2       3  0.500000 \n",
      "\n",
      "      Sex  Survived\n",
      "0  female  0.931818\n",
      "1    male  0.431579 \n",
      "\n",
      "             Age  Survived\n",
      "0  (-0.08, 16.0]  0.875000\n",
      "1   (16.0, 32.0]  0.737705\n",
      "2   (32.0, 48.0]  0.661538\n",
      "3   (48.0, 64.0]  0.555556\n",
      "4   (64.0, 80.0]  0.200000 \n",
      "\n",
      "                 Fare  Survived\n",
      "3  (384.247, 512.329]  1.000000\n",
      "1  (128.082, 256.165]  0.750000\n",
      "2  (256.165, 384.247]  0.666667\n",
      "0   (-0.512, 128.082]  0.658065 \n",
      "\n",
      "  Embarked  Survived\n",
      "0        C  0.738462\n",
      "2        S  0.637931\n",
      "1        Q  0.500000 \n",
      "\n",
      "  NameTitle  Survived\n",
      "0    Master  1.000000\n",
      "5   royalty  1.000000\n",
      "1      Miss  0.934783\n",
      "3       Mrs  0.923077\n",
      "4   officer  0.571429\n",
      "2        Mr  0.370370 \n",
      "\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Replace Type to Number：{Female, Male} = {0, 1}\n",
      "Class： [(32.0, 48.0], (48.0, 64.0], (-0.08, 16.0], (16.0, 32.0], (64.0, 80.0]]\n",
      "Categories (5, interval[float64]): [(-0.08, 16.0] < (16.0, 32.0] < (32.0, 48.0] < (48.0, 64.0] < (64.0, 80.0]]\n",
      "Class： ['C' 'S' 'Q']\n",
      "Class： [(-0.512, 128.082], (256.165, 384.247], (128.082, 256.165], (384.247, 512.329]]\n",
      "Categories (4, interval[float64]): [(-0.512, 128.082] < (128.082, 256.165] < (256.165, 384.247] < (384.247, 512.329]]\n",
      "Class： ['female' 'male']\n",
      "Class： ['Mrs' 'Mr' 'Miss' 'Master' 'officer' 'royalty']\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "write csv\n",
      "new_train：\n",
      "    Age  Embarked  Fare  Parch  PassengerId  Pclass  Sex  SibSp  Survived  \\\n",
      "1     2         0     0      0            2       1    0      1       1.0   \n",
      "3     2         2     0      0            4       1    0      1       1.0   \n",
      "6     3         2     0      0            7       1    1      0       0.0   \n",
      "10    0         2     0      1           11       3    0      1       1.0   \n",
      "11    3         2     0      0           12       1    0      0       1.0   \n",
      "21    2         2     0      0           22       2    1      0       1.0   \n",
      "23    1         2     0      0           24       1    1      0       1.0   \n",
      "27    1         2     2      2           28       1    1      3       0.0   \n",
      "52    3         0     0      0           53       1    0      1       1.0   \n",
      "54    4         0     0      1           55       1    1      0       0.0   \n",
      "\n",
      "    NameTitle  \n",
      "1           3  \n",
      "3           3  \n",
      "6           2  \n",
      "10          1  \n",
      "11          1  \n",
      "21          2  \n",
      "23          2  \n",
      "27          2  \n",
      "52          3  \n",
      "54          2  \n",
      "\n",
      "dtypes：\n",
      "Age              int32\n",
      "Embarked         int32\n",
      "Fare             int32\n",
      "Parch            int64\n",
      "PassengerId      int64\n",
      "Pclass           int64\n",
      "Sex              int32\n",
      "SibSp            int64\n",
      "Survived       float64\n",
      "NameTitle        int32\n",
      "dtype: object\n",
      "\n",
      "new_test：\n",
      "   Age  Embarked  Fare  Parch  PassengerId  Pclass  Sex  SibSp  NameTitle\n",
      "0    2         1     0      0          892       3    1      0          2\n",
      "1    2         2     0      0          893       3    0      1          3\n",
      "2    3         1     0      0          894       2    1      0          2\n",
      "3    1         2     0      0          895       3    1      0          2\n",
      "4    1         2     0      1          896       3    0      1          3\n",
      "5    0         2     0      0          897       3    1      0          2\n",
      "6    1         1     0      0          898       3    0      0          1\n",
      "7    1         2     0      1          899       2    1      1          2\n",
      "8    1         0     0      0          900       3    0      0          3\n",
      "9    1         2     0      0          901       3    1      2          2\n",
      "\n",
      "dtypes：\n",
      "Age            int32\n",
      "Embarked       int32\n",
      "Fare           int32\n",
      "Parch          int64\n",
      "PassengerId    int64\n",
      "Pclass         int64\n",
      "Sex            int32\n",
      "SibSp          int64\n",
      "NameTitle      int32\n",
      "dtype: object\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     讀取資料\n",
    "    readPath = './Data/train.csv'\n",
    "    readPath2 = './Data/test.csv'\n",
    "    writePath = './Data/new_train.csv'\n",
    "    writePath2 = './Data/new_test.csv'\n",
    "    data = pd.read_csv(readPath)\n",
    "    data2 = pd.read_csv(readPath2)\n",
    "    data['Type'] = 'Train'\n",
    "    data2['Type'] = 'Test'\n",
    "                        \n",
    "#     ------------------------------------------------------------------------------------\n",
    "#   Train 前處理    \n",
    "#     移除NAN數值\n",
    "    data = data.dropna()\n",
    "#     ------------------------------------------------------------------------------------\n",
    "#     合併資料處理\n",
    "#     合併資料\n",
    "    dataMerge = pd.concat([data, data2], sort=True)\n",
    "    \n",
    "#     Age = NAN值 Replace 0\n",
    "    dataMerge['Age'] = dataMerge['Age'].fillna(0)\n",
    "    \n",
    "#     保留名稱稱謂\n",
    "    dataMerge['NameTitle'] = dataMerge['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "        \n",
    "#     利用qcut將Age調整為五個區間 # qcut 主要是透過總數量進行區分\n",
    "    dataMerge['Age'] = pd.cut(dataMerge['Age'], 5)\n",
    "    \n",
    "#     利用cut將Fare調整為五個區間 # cut 主要是將總量作為五個區間進行分類\n",
    "    dataMerge['Fare'] = dataMerge['Fare'].fillna(0)\n",
    "    dataMerge['Fare'] = pd.cut(dataMerge['Fare'], 4)\n",
    "    \n",
    "#     比較名稱稱謂與性別的總數，判斷哪些稱謂可以合併\n",
    "    dataMerge['NameTitle'] = dataMerge['NameTitle'].replace('Mlle', 'Miss')\n",
    "    dataMerge['NameTitle'] = dataMerge['NameTitle'].replace('Ms', 'Miss')\n",
    "    dataMerge['NameTitle'] = dataMerge['NameTitle'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Reassign rare titles\n",
    "    dataMerge.loc[(dataMerge['NameTitle'] == 'Capt') | \n",
    "               (dataMerge['NameTitle'] == 'Col') |\n",
    "               (dataMerge['NameTitle'] == 'Don') |\n",
    "               (dataMerge['NameTitle'] == 'Dr') |\n",
    "               (dataMerge['NameTitle'] == 'Major') |\n",
    "               (dataMerge['NameTitle'] == 'Rev'), 'NameTitle'] = 'officer'\n",
    "    \n",
    "    dataMerge.loc[(dataMerge['NameTitle'] == 'Dona') | \n",
    "               (dataMerge['NameTitle'] == 'Lady') |\n",
    "               (dataMerge['NameTitle'] == 'Countess') |\n",
    "               (dataMerge['NameTitle'] == 'Sir') |\n",
    "               (dataMerge['NameTitle'] == 'Jonkheer'), 'NameTitle'] = 'royalty'\n",
    "\n",
    "#     比較各類別與Survived的關聯性\n",
    "    print('----------------------------------------')\n",
    "    print('Compare Association Between Type')\n",
    "    print(CompareAssBetType(dataMerge, 'Pclass', 'Survived'), '\\n')    \n",
    "    print(CompareAssBetType(dataMerge, 'Sex', 'Survived'), '\\n')\n",
    "    print(CompareAssBetType(dataMerge, 'Age', 'Survived'), '\\n')\n",
    "    print(CompareAssBetType(dataMerge, 'Fare', 'Survived'), '\\n')\n",
    "    print(CompareAssBetType(dataMerge, 'Embarked', 'Survived'), '\\n')\n",
    "    print(CompareAssBetType(dataMerge, 'NameTitle', 'Survived'), '\\n')\n",
    "    print('----------------------------------------')\n",
    "    \n",
    "#     類別替換成數字\n",
    "    print('----------------------------------------')\n",
    "    print('Replace Type to Number：{Female, Male} = {0, 1}')\n",
    "    dataMerge['Age'] = ReplaceTypeToNum(dataMerge['Age'])\n",
    "    dataMerge['Embarked'] = ReplaceTypeToNum(dataMerge['Embarked'])\n",
    "    dataMerge['Fare'] = ReplaceTypeToNum(dataMerge['Fare'])\n",
    "    dataMerge['Sex'] = ReplaceTypeToNum(dataMerge['Sex'])\n",
    "    dataMerge['NameTitle'] = ReplaceTypeToNum(dataMerge['NameTitle'])\n",
    "    print('----------------------------------------')\n",
    "    \n",
    "#     移除不必要資料\n",
    "    dataMerge = dataMerge.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "#     ------------------------------------------------------------------------------------\n",
    "#     拆開合併資料\n",
    "    data = dataMerge[dataMerge['Type'] == 'Train']\n",
    "    data2 = dataMerge[dataMerge['Type'] == 'Test']\n",
    "    data = data.drop(columns=['Type'])\n",
    "    data2 = data2.drop(columns=['Type', 'Survived'])\n",
    "    \n",
    "# #     選擇特徵值\n",
    "#     print('----------------------------------------')\n",
    "#     print('Select Feature')\n",
    "#     data, data2 = SelectFeature(data, data2)\n",
    "#     print('----------------------------------------')\n",
    "        \n",
    "#     輸出資料\n",
    "    print('----------------------------------------')\n",
    "    print('write csv')\n",
    "    print('new_train：')\n",
    "    print(data.head(10))\n",
    "    print('\\ndtypes：')\n",
    "    print(data.dtypes)\n",
    "    print('\\nnew_test：')\n",
    "    print(data2.head(10))\n",
    "    print('\\ndtypes：')\n",
    "    print(data2.dtypes)\n",
    "    \n",
    "    data.to_csv(writePath, index=False)\n",
    "    data2.to_csv(writePath2, index=False)\n",
    "    print('----------------------------------------')\n",
    "#     ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train： (146, 8)\n",
      "y_train： (146,)\n",
      "x_val： (37, 8)\n",
      "y_val： (37,)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 34,433\n",
      "Trainable params: 34,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 146 samples, validate on 37 samples\n",
      "Epoch 1/2000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.54798, saving model to ./Model/Train_01_0.5205_2.5555_0.5676_2.5480.h5\n",
      "146/146 [==============================] - 1s 10ms/sample - loss: 2.5555 - accuracy: 0.5205 - val_loss: 2.5480 - val_accuracy: 0.5676\n",
      "Epoch 2/2000\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.280192). Check your callbacks.\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.54798 to 2.52923, saving model to ./Model/Train_02_0.6438_2.4912_0.5676_2.5292.h5\n",
      "146/146 [==============================] - 0s 3ms/sample - loss: 2.4912 - accuracy: 0.6438 - val_loss: 2.5292 - val_accuracy: 0.5676\n",
      "Epoch 3/2000\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.52923 to 2.50689, saving model to ./Model/Train_03_0.6986_2.4413_0.5676_2.5069.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 2.4413 - accuracy: 0.6986 - val_loss: 2.5069 - val_accuracy: 0.5676\n",
      "Epoch 4/2000\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.50689 to 2.48124, saving model to ./Model/Train_04_0.7123_2.3774_0.5676_2.4812.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 2.3774 - accuracy: 0.7123 - val_loss: 2.4812 - val_accuracy: 0.5676\n",
      "Epoch 5/2000\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.48124 to 2.44756, saving model to ./Model/Train_05_0.6986_2.3650_0.5676_2.4476.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 2.3650 - accuracy: 0.6986 - val_loss: 2.4476 - val_accuracy: 0.5676\n",
      "Epoch 6/2000\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.44756 to 2.40695, saving model to ./Model/Train_06_0.6918_2.3533_0.5676_2.4070.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 2.3533 - accuracy: 0.6918 - val_loss: 2.4070 - val_accuracy: 0.5676\n",
      "Epoch 7/2000\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.40695 to 2.36433, saving model to ./Model/Train_07_0.6918_2.2985_0.5676_2.3643.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 2.2985 - accuracy: 0.6918 - val_loss: 2.3643 - val_accuracy: 0.5676\n",
      "Epoch 8/2000\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.36433 to 2.31946, saving model to ./Model/Train_08_0.6986_2.2452_0.5676_2.3195.h5\n",
      "146/146 [==============================] - 0s 831us/sample - loss: 2.2452 - accuracy: 0.6986 - val_loss: 2.3195 - val_accuracy: 0.5676\n",
      "Epoch 9/2000\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.31946 to 2.27447, saving model to ./Model/Train_09_0.7055_2.2090_0.5676_2.2745.h5\n",
      "146/146 [==============================] - 0s 630us/sample - loss: 2.2090 - accuracy: 0.7055 - val_loss: 2.2745 - val_accuracy: 0.5676\n",
      "Epoch 10/2000\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.27447 to 2.22914, saving model to ./Model/Train_10_0.6986_2.2127_0.5676_2.2291.h5\n",
      "146/146 [==============================] - 0s 574us/sample - loss: 2.2127 - accuracy: 0.6986 - val_loss: 2.2291 - val_accuracy: 0.5676\n",
      "Epoch 11/2000\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.22914 to 2.18553, saving model to ./Model/Train_11_0.6849_2.1561_0.5676_2.1855.h5\n",
      "146/146 [==============================] - 0s 716us/sample - loss: 2.1561 - accuracy: 0.6849 - val_loss: 2.1855 - val_accuracy: 0.5676\n",
      "Epoch 12/2000\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.18553 to 2.14340, saving model to ./Model/Train_12_0.6918_2.1265_0.5676_2.1434.h5\n",
      "146/146 [==============================] - 0s 617us/sample - loss: 2.1265 - accuracy: 0.6918 - val_loss: 2.1434 - val_accuracy: 0.5676\n",
      "Epoch 13/2000\n",
      "\n",
      "Epoch 00013: val_loss improved from 2.14340 to 2.10415, saving model to ./Model/Train_13_0.6986_2.0732_0.5676_2.1042.h5\n",
      "146/146 [==============================] - 0s 574us/sample - loss: 2.0732 - accuracy: 0.6986 - val_loss: 2.1042 - val_accuracy: 0.5676\n",
      "Epoch 14/2000\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.10415 to 2.06692, saving model to ./Model/Train_14_0.6918_2.0606_0.5676_2.0669.h5\n",
      "146/146 [==============================] - 0s 884us/sample - loss: 2.0606 - accuracy: 0.6918 - val_loss: 2.0669 - val_accuracy: 0.5676\n",
      "Epoch 15/2000\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.06692 to 2.03139, saving model to ./Model/Train_15_0.7055_2.0335_0.5676_2.0314.h5\n",
      "146/146 [==============================] - 0s 631us/sample - loss: 2.0335 - accuracy: 0.7055 - val_loss: 2.0314 - val_accuracy: 0.5676\n",
      "Epoch 16/2000\n",
      "\n",
      "Epoch 00016: val_loss improved from 2.03139 to 1.99759, saving model to ./Model/Train_16_0.6712_1.9913_0.5676_1.9976.h5\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 1.9913 - accuracy: 0.6712 - val_loss: 1.9976 - val_accuracy: 0.5676\n",
      "Epoch 17/2000\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.99759 to 1.96520, saving model to ./Model/Train_17_0.6986_1.9611_0.5676_1.9652.h5\n",
      "146/146 [==============================] - 0s 720us/sample - loss: 1.9611 - accuracy: 0.6986 - val_loss: 1.9652 - val_accuracy: 0.5676\n",
      "Epoch 18/2000\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.96520 to 1.93362, saving model to ./Model/Train_18_0.7397_1.9102_0.5676_1.9336.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.9102 - accuracy: 0.7397 - val_loss: 1.9336 - val_accuracy: 0.5676\n",
      "Epoch 19/2000\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.93362 to 1.90306, saving model to ./Model/Train_19_0.6918_1.8884_0.5676_1.9031.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 1.8884 - accuracy: 0.6918 - val_loss: 1.9031 - val_accuracy: 0.5676\n",
      "Epoch 20/2000\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.90306 to 1.87337, saving model to ./Model/Train_20_0.7192_1.8525_0.5676_1.8734.h5\n",
      "146/146 [==============================] - 0s 565us/sample - loss: 1.8525 - accuracy: 0.7192 - val_loss: 1.8734 - val_accuracy: 0.5676\n",
      "Epoch 21/2000\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.87337 to 1.84487, saving model to ./Model/Train_21_0.6986_1.8525_0.5676_1.8449.h5\n",
      "146/146 [==============================] - 0s 559us/sample - loss: 1.8525 - accuracy: 0.6986 - val_loss: 1.8449 - val_accuracy: 0.5676\n",
      "Epoch 22/2000\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.84487 to 1.81757, saving model to ./Model/Train_22_0.7192_1.8167_0.5676_1.8176.h5\n",
      "146/146 [==============================] - 0s 616us/sample - loss: 1.8167 - accuracy: 0.7192 - val_loss: 1.8176 - val_accuracy: 0.5676\n",
      "Epoch 23/2000\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.81757 to 1.79141, saving model to ./Model/Train_23_0.6986_1.8060_0.5676_1.7914.h5\n",
      "146/146 [==============================] - 0s 978us/sample - loss: 1.8060 - accuracy: 0.6986 - val_loss: 1.7914 - val_accuracy: 0.5676\n",
      "Epoch 24/2000\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.79141 to 1.76593, saving model to ./Model/Train_24_0.7123_1.7548_0.5676_1.7659.h5\n",
      "146/146 [==============================] - 0s 724us/sample - loss: 1.7548 - accuracy: 0.7123 - val_loss: 1.7659 - val_accuracy: 0.5676\n",
      "Epoch 25/2000\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.76593 to 1.74066, saving model to ./Model/Train_25_0.7534_1.7066_0.5676_1.7407.h5\n",
      "146/146 [==============================] - 0s 656us/sample - loss: 1.7066 - accuracy: 0.7534 - val_loss: 1.7407 - val_accuracy: 0.5676\n",
      "Epoch 26/2000\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.74066 to 1.71573, saving model to ./Model/Train_26_0.6986_1.6915_0.5676_1.7157.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.6915 - accuracy: 0.6986 - val_loss: 1.7157 - val_accuracy: 0.5676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/2000\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.71573 to 1.69090, saving model to ./Model/Train_27_0.7192_1.6931_0.5676_1.6909.h5\n",
      "146/146 [==============================] - 0s 776us/sample - loss: 1.6931 - accuracy: 0.7192 - val_loss: 1.6909 - val_accuracy: 0.5676\n",
      "Epoch 28/2000\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.69090 to 1.66606, saving model to ./Model/Train_28_0.7123_1.6365_0.5676_1.6661.h5\n",
      "146/146 [==============================] - 0s 565us/sample - loss: 1.6365 - accuracy: 0.7123 - val_loss: 1.6661 - val_accuracy: 0.5676\n",
      "Epoch 29/2000\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.66606 to 1.64155, saving model to ./Model/Train_29_0.7397_1.6265_0.5946_1.6415.h5\n",
      "146/146 [==============================] - 0s 569us/sample - loss: 1.6265 - accuracy: 0.7397 - val_loss: 1.6415 - val_accuracy: 0.5946\n",
      "Epoch 30/2000\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.64155 to 1.61629, saving model to ./Model/Train_30_0.7055_1.6063_0.6486_1.6163.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.6063 - accuracy: 0.7055 - val_loss: 1.6163 - val_accuracy: 0.6486\n",
      "Epoch 31/2000\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.61629 to 1.59173, saving model to ./Model/Train_31_0.7534_1.5988_0.6486_1.5917.h5\n",
      "146/146 [==============================] - 0s 547us/sample - loss: 1.5988 - accuracy: 0.7534 - val_loss: 1.5917 - val_accuracy: 0.6486\n",
      "Epoch 32/2000\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.59173 to 1.56709, saving model to ./Model/Train_32_0.7055_1.5635_0.6486_1.5671.h5\n",
      "146/146 [==============================] - 0s 694us/sample - loss: 1.5635 - accuracy: 0.7055 - val_loss: 1.5671 - val_accuracy: 0.6486\n",
      "Epoch 33/2000\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.56709 to 1.54221, saving model to ./Model/Train_33_0.7123_1.5279_0.6486_1.5422.h5\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 1.5279 - accuracy: 0.7123 - val_loss: 1.5422 - val_accuracy: 0.6486\n",
      "Epoch 34/2000\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.54221 to 1.51821, saving model to ./Model/Train_34_0.7192_1.5156_0.6757_1.5182.h5\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 1.5156 - accuracy: 0.7192 - val_loss: 1.5182 - val_accuracy: 0.6757\n",
      "Epoch 35/2000\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.51821 to 1.49450, saving model to ./Model/Train_35_0.7260_1.4806_0.7027_1.4945.h5\n",
      "146/146 [==============================] - 0s 740us/sample - loss: 1.4806 - accuracy: 0.7260 - val_loss: 1.4945 - val_accuracy: 0.7027\n",
      "Epoch 36/2000\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.49450 to 1.47129, saving model to ./Model/Train_36_0.7466_1.4580_0.7027_1.4713.h5\n",
      "146/146 [==============================] - 0s 728us/sample - loss: 1.4580 - accuracy: 0.7466 - val_loss: 1.4713 - val_accuracy: 0.7027\n",
      "Epoch 37/2000\n",
      "\n",
      "Epoch 00037: val_loss improved from 1.47129 to 1.44900, saving model to ./Model/Train_37_0.7123_1.4528_0.7297_1.4490.h5\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 1.4528 - accuracy: 0.7123 - val_loss: 1.4490 - val_accuracy: 0.7297\n",
      "Epoch 38/2000\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.44900 to 1.42790, saving model to ./Model/Train_38_0.7260_1.4171_0.7297_1.4279.h5\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 1.4171 - accuracy: 0.7260 - val_loss: 1.4279 - val_accuracy: 0.7297\n",
      "Epoch 39/2000\n",
      "\n",
      "Epoch 00039: val_loss improved from 1.42790 to 1.40702, saving model to ./Model/Train_39_0.7260_1.3953_0.7297_1.4070.h5\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 1.3953 - accuracy: 0.7260 - val_loss: 1.4070 - val_accuracy: 0.7297\n",
      "Epoch 40/2000\n",
      "\n",
      "Epoch 00040: val_loss improved from 1.40702 to 1.38693, saving model to ./Model/Train_40_0.7671_1.3769_0.7297_1.3869.h5\n",
      "146/146 [==============================] - 0s 742us/sample - loss: 1.3769 - accuracy: 0.7671 - val_loss: 1.3869 - val_accuracy: 0.7297\n",
      "Epoch 41/2000\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.38693 to 1.36744, saving model to ./Model/Train_41_0.7329_1.3746_0.7027_1.3674.h5\n",
      "146/146 [==============================] - 0s 941us/sample - loss: 1.3746 - accuracy: 0.7329 - val_loss: 1.3674 - val_accuracy: 0.7027\n",
      "Epoch 42/2000\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.36744 to 1.34854, saving model to ./Model/Train_42_0.7192_1.3476_0.7027_1.3485.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 1.3476 - accuracy: 0.7192 - val_loss: 1.3485 - val_accuracy: 0.7027\n",
      "Epoch 43/2000\n",
      "\n",
      "Epoch 00043: val_loss improved from 1.34854 to 1.33027, saving model to ./Model/Train_43_0.7055_1.3440_0.7027_1.3303.h5\n",
      "146/146 [==============================] - 0s 858us/sample - loss: 1.3440 - accuracy: 0.7055 - val_loss: 1.3303 - val_accuracy: 0.7027\n",
      "Epoch 44/2000\n",
      "\n",
      "Epoch 00044: val_loss improved from 1.33027 to 1.31238, saving model to ./Model/Train_44_0.6986_1.3308_0.7027_1.3124.h5\n",
      "146/146 [==============================] - 0s 898us/sample - loss: 1.3308 - accuracy: 0.6986 - val_loss: 1.3124 - val_accuracy: 0.7027\n",
      "Epoch 45/2000\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.31238 to 1.29460, saving model to ./Model/Train_45_0.7260_1.2973_0.7297_1.2946.h5\n",
      "146/146 [==============================] - 0s 888us/sample - loss: 1.2973 - accuracy: 0.7260 - val_loss: 1.2946 - val_accuracy: 0.7297\n",
      "Epoch 46/2000\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.29460 to 1.27731, saving model to ./Model/Train_46_0.7534_1.2636_0.7297_1.2773.h5\n",
      "146/146 [==============================] - 0s 810us/sample - loss: 1.2636 - accuracy: 0.7534 - val_loss: 1.2773 - val_accuracy: 0.7297\n",
      "Epoch 47/2000\n",
      "\n",
      "Epoch 00047: val_loss improved from 1.27731 to 1.26061, saving model to ./Model/Train_47_0.7877_1.2279_0.7297_1.2606.h5\n",
      "146/146 [==============================] - 0s 936us/sample - loss: 1.2279 - accuracy: 0.7877 - val_loss: 1.2606 - val_accuracy: 0.7297\n",
      "Epoch 48/2000\n",
      "\n",
      "Epoch 00048: val_loss improved from 1.26061 to 1.24408, saving model to ./Model/Train_48_0.7603_1.2340_0.7297_1.2441.h5\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 1.2340 - accuracy: 0.7603 - val_loss: 1.2441 - val_accuracy: 0.7297\n",
      "Epoch 49/2000\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.24408 to 1.22732, saving model to ./Model/Train_49_0.7534_1.2079_0.7297_1.2273.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.2079 - accuracy: 0.7534 - val_loss: 1.2273 - val_accuracy: 0.7297\n",
      "Epoch 50/2000\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.22732 to 1.21117, saving model to ./Model/Train_50_0.7260_1.2050_0.7297_1.2112.h5\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 1.2050 - accuracy: 0.7260 - val_loss: 1.2112 - val_accuracy: 0.7297\n",
      "Epoch 51/2000\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.21117 to 1.19599, saving model to ./Model/Train_51_0.7329_1.1934_0.7297_1.1960.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.1934 - accuracy: 0.7329 - val_loss: 1.1960 - val_accuracy: 0.7297\n",
      "Epoch 52/2000\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.19599 to 1.18153, saving model to ./Model/Train_52_0.7123_1.1985_0.7297_1.1815.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 1.1985 - accuracy: 0.7123 - val_loss: 1.1815 - val_accuracy: 0.7297\n",
      "Epoch 53/2000\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.18153 to 1.16696, saving model to ./Model/Train_53_0.7603_1.1536_0.7297_1.1670.h5\n",
      "146/146 [==============================] - 0s 919us/sample - loss: 1.1536 - accuracy: 0.7603 - val_loss: 1.1670 - val_accuracy: 0.7297\n",
      "Epoch 54/2000\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.16696 to 1.15307, saving model to ./Model/Train_54_0.7192_1.1505_0.7297_1.1531.h5\n",
      "146/146 [==============================] - 0s 942us/sample - loss: 1.1505 - accuracy: 0.7192 - val_loss: 1.1531 - val_accuracy: 0.7297\n",
      "Epoch 55/2000\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.15307 to 1.13918, saving model to ./Model/Train_55_0.7603_1.1085_0.7297_1.1392.h5\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 1.1085 - accuracy: 0.7603 - val_loss: 1.1392 - val_accuracy: 0.7297\n",
      "Epoch 56/2000\n",
      "\n",
      "Epoch 00056: val_loss improved from 1.13918 to 1.12506, saving model to ./Model/Train_56_0.7397_1.1149_0.7297_1.1251.h5\n",
      "146/146 [==============================] - 0s 907us/sample - loss: 1.1149 - accuracy: 0.7397 - val_loss: 1.1251 - val_accuracy: 0.7297\n",
      "Epoch 57/2000\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.12506 to 1.11125, saving model to ./Model/Train_57_0.7397_1.1053_0.7297_1.1113.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 854us/sample - loss: 1.1053 - accuracy: 0.7397 - val_loss: 1.1113 - val_accuracy: 0.7297\n",
      "Epoch 58/2000\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.11125 to 1.09778, saving model to ./Model/Train_58_0.7671_1.0680_0.8108_1.0978.h5\n",
      "146/146 [==============================] - 0s 905us/sample - loss: 1.0680 - accuracy: 0.7671 - val_loss: 1.0978 - val_accuracy: 0.8108\n",
      "Epoch 59/2000\n",
      "\n",
      "Epoch 00059: val_loss improved from 1.09778 to 1.08543, saving model to ./Model/Train_59_0.7534_1.0793_0.7838_1.0854.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.0793 - accuracy: 0.7534 - val_loss: 1.0854 - val_accuracy: 0.7838\n",
      "Epoch 60/2000\n",
      "\n",
      "Epoch 00060: val_loss improved from 1.08543 to 1.07358, saving model to ./Model/Train_60_0.7329_1.0696_0.7838_1.0736.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 1.0696 - accuracy: 0.7329 - val_loss: 1.0736 - val_accuracy: 0.7838\n",
      "Epoch 61/2000\n",
      "\n",
      "Epoch 00061: val_loss improved from 1.07358 to 1.06235, saving model to ./Model/Train_61_0.7123_1.0734_0.7838_1.0623.h5\n",
      "146/146 [==============================] - 0s 914us/sample - loss: 1.0734 - accuracy: 0.7123 - val_loss: 1.0623 - val_accuracy: 0.7838\n",
      "Epoch 62/2000\n",
      "\n",
      "Epoch 00062: val_loss improved from 1.06235 to 1.05174, saving model to ./Model/Train_62_0.7260_1.0387_0.7568_1.0517.h5\n",
      "146/146 [==============================] - 0s 940us/sample - loss: 1.0387 - accuracy: 0.7260 - val_loss: 1.0517 - val_accuracy: 0.7568\n",
      "Epoch 63/2000\n",
      "\n",
      "Epoch 00063: val_loss improved from 1.05174 to 1.04134, saving model to ./Model/Train_63_0.7466_1.0220_0.7297_1.0413.h5\n",
      "146/146 [==============================] - 0s 908us/sample - loss: 1.0220 - accuracy: 0.7466 - val_loss: 1.0413 - val_accuracy: 0.7297\n",
      "Epoch 64/2000\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.04134 to 1.03082, saving model to ./Model/Train_64_0.7534_0.9780_0.7297_1.0308.h5\n",
      "146/146 [==============================] - 0s 845us/sample - loss: 0.9780 - accuracy: 0.7534 - val_loss: 1.0308 - val_accuracy: 0.7297\n",
      "Epoch 65/2000\n",
      "\n",
      "Epoch 00065: val_loss improved from 1.03082 to 1.01978, saving model to ./Model/Train_65_0.7603_0.9937_0.7568_1.0198.h5\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.9937 - accuracy: 0.7603 - val_loss: 1.0198 - val_accuracy: 0.7568\n",
      "Epoch 66/2000\n",
      "\n",
      "Epoch 00066: val_loss improved from 1.01978 to 1.00936, saving model to ./Model/Train_66_0.7329_0.9911_0.7568_1.0094.h5\n",
      "146/146 [==============================] - 0s 905us/sample - loss: 0.9911 - accuracy: 0.7329 - val_loss: 1.0094 - val_accuracy: 0.7568\n",
      "Epoch 67/2000\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.00936 to 1.00006, saving model to ./Model/Train_67_0.7877_0.9723_0.7297_1.0001.h5\n",
      "146/146 [==============================] - 0s 801us/sample - loss: 0.9723 - accuracy: 0.7877 - val_loss: 1.0001 - val_accuracy: 0.7297\n",
      "Epoch 68/2000\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.00006 to 0.99045, saving model to ./Model/Train_68_0.7671_0.9672_0.7297_0.9905.h5\n",
      "146/146 [==============================] - 0s 916us/sample - loss: 0.9672 - accuracy: 0.7671 - val_loss: 0.9905 - val_accuracy: 0.7297\n",
      "Epoch 69/2000\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.99045 to 0.98064, saving model to ./Model/Train_69_0.7260_0.9802_0.7297_0.9806.h5\n",
      "146/146 [==============================] - 0s 936us/sample - loss: 0.9802 - accuracy: 0.7260 - val_loss: 0.9806 - val_accuracy: 0.7297\n",
      "Epoch 70/2000\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.98064 to 0.97068, saving model to ./Model/Train_70_0.7329_0.9474_0.7297_0.9707.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.9474 - accuracy: 0.7329 - val_loss: 0.9707 - val_accuracy: 0.7297\n",
      "Epoch 71/2000\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.97068 to 0.96014, saving model to ./Model/Train_71_0.7740_0.9180_0.7568_0.9601.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.9180 - accuracy: 0.7740 - val_loss: 0.9601 - val_accuracy: 0.7568\n",
      "Epoch 72/2000\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.96014 to 0.95027, saving model to ./Model/Train_72_0.7329_0.9472_0.7568_0.9503.h5\n",
      "146/146 [==============================] - 0s 799us/sample - loss: 0.9472 - accuracy: 0.7329 - val_loss: 0.9503 - val_accuracy: 0.7568\n",
      "Epoch 73/2000\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.95027 to 0.94046, saving model to ./Model/Train_73_0.7877_0.9190_0.7838_0.9405.h5\n",
      "146/146 [==============================] - 0s 852us/sample - loss: 0.9190 - accuracy: 0.7877 - val_loss: 0.9405 - val_accuracy: 0.7838\n",
      "Epoch 74/2000\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.94046 to 0.92987, saving model to ./Model/Train_74_0.7260_0.9226_0.7838_0.9299.h5\n",
      "146/146 [==============================] - 0s 796us/sample - loss: 0.9226 - accuracy: 0.7260 - val_loss: 0.9299 - val_accuracy: 0.7838\n",
      "Epoch 75/2000\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.92987 to 0.91964, saving model to ./Model/Train_75_0.7329_0.9142_0.7568_0.9196.h5\n",
      "146/146 [==============================] - 0s 850us/sample - loss: 0.9142 - accuracy: 0.7329 - val_loss: 0.9196 - val_accuracy: 0.7568\n",
      "Epoch 76/2000\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.91964 to 0.91047, saving model to ./Model/Train_76_0.7397_0.8889_0.7568_0.9105.h5\n",
      "146/146 [==============================] - 0s 844us/sample - loss: 0.8889 - accuracy: 0.7397 - val_loss: 0.9105 - val_accuracy: 0.7568\n",
      "Epoch 77/2000\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.91047 to 0.90203, saving model to ./Model/Train_77_0.7466_0.8827_0.7568_0.9020.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.8827 - accuracy: 0.7466 - val_loss: 0.9020 - val_accuracy: 0.7568\n",
      "Epoch 78/2000\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.90203 to 0.89451, saving model to ./Model/Train_78_0.7329_0.8835_0.7568_0.8945.h5\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.8835 - accuracy: 0.7329 - val_loss: 0.8945 - val_accuracy: 0.7568\n",
      "Epoch 79/2000\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.89451 to 0.88745, saving model to ./Model/Train_79_0.7603_0.8702_0.7568_0.8875.h5\n",
      "146/146 [==============================] - 0s 790us/sample - loss: 0.8702 - accuracy: 0.7603 - val_loss: 0.8875 - val_accuracy: 0.7568\n",
      "Epoch 80/2000\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.88745 to 0.88025, saving model to ./Model/Train_80_0.7603_0.8537_0.7838_0.8802.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.8537 - accuracy: 0.7603 - val_loss: 0.8802 - val_accuracy: 0.7838\n",
      "Epoch 81/2000\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.88025 to 0.87376, saving model to ./Model/Train_81_0.7329_0.8611_0.7838_0.8738.h5\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.8611 - accuracy: 0.7329 - val_loss: 0.8738 - val_accuracy: 0.7838\n",
      "Epoch 82/2000\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.87376 to 0.86746, saving model to ./Model/Train_82_0.7808_0.8363_0.7838_0.8675.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.8363 - accuracy: 0.7808 - val_loss: 0.8675 - val_accuracy: 0.7838\n",
      "Epoch 83/2000\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.86746 to 0.86029, saving model to ./Model/Train_83_0.7534_0.8418_0.7838_0.8603.h5\n",
      "146/146 [==============================] - 0s 884us/sample - loss: 0.8418 - accuracy: 0.7534 - val_loss: 0.8603 - val_accuracy: 0.7838\n",
      "Epoch 84/2000\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.86029 to 0.85353, saving model to ./Model/Train_84_0.7671_0.8131_0.7838_0.8535.h5\n",
      "146/146 [==============================] - 0s 966us/sample - loss: 0.8131 - accuracy: 0.7671 - val_loss: 0.8535 - val_accuracy: 0.7838\n",
      "Epoch 85/2000\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.85353 to 0.84688, saving model to ./Model/Train_85_0.7329_0.8328_0.7838_0.8469.h5\n",
      "146/146 [==============================] - 0s 990us/sample - loss: 0.8328 - accuracy: 0.7329 - val_loss: 0.8469 - val_accuracy: 0.7838\n",
      "Epoch 86/2000\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.84688 to 0.84001, saving model to ./Model/Train_86_0.7740_0.7859_0.7838_0.8400.h5\n",
      "146/146 [==============================] - 0s 912us/sample - loss: 0.7859 - accuracy: 0.7740 - val_loss: 0.8400 - val_accuracy: 0.7838\n",
      "Epoch 87/2000\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.84001 to 0.83314, saving model to ./Model/Train_87_0.7671_0.8002_0.7838_0.8331.h5\n",
      "146/146 [==============================] - 0s 901us/sample - loss: 0.8002 - accuracy: 0.7671 - val_loss: 0.8331 - val_accuracy: 0.7838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/2000\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.83314 to 0.82630, saving model to ./Model/Train_88_0.7671_0.8178_0.7838_0.8263.h5\n",
      "146/146 [==============================] - 0s 877us/sample - loss: 0.8178 - accuracy: 0.7671 - val_loss: 0.8263 - val_accuracy: 0.7838\n",
      "Epoch 89/2000\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.82630 to 0.81984, saving model to ./Model/Train_89_0.7877_0.7770_0.7838_0.8198.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.7770 - accuracy: 0.7877 - val_loss: 0.8198 - val_accuracy: 0.7838\n",
      "Epoch 90/2000\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.81984 to 0.81326, saving model to ./Model/Train_90_0.7603_0.7536_0.7568_0.8133.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.7536 - accuracy: 0.7603 - val_loss: 0.8133 - val_accuracy: 0.7568\n",
      "Epoch 91/2000\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.81326 to 0.80686, saving model to ./Model/Train_91_0.7671_0.7886_0.7568_0.8069.h5\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.7886 - accuracy: 0.7671 - val_loss: 0.8069 - val_accuracy: 0.7568\n",
      "Epoch 92/2000\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.80686 to 0.80143, saving model to ./Model/Train_92_0.7808_0.7637_0.7568_0.8014.h5\n",
      "146/146 [==============================] - 0s 799us/sample - loss: 0.7637 - accuracy: 0.7808 - val_loss: 0.8014 - val_accuracy: 0.7568\n",
      "Epoch 93/2000\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.80143 to 0.79721, saving model to ./Model/Train_93_0.7534_0.7619_0.7838_0.7972.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.7619 - accuracy: 0.7534 - val_loss: 0.7972 - val_accuracy: 0.7838\n",
      "Epoch 94/2000\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.79721 to 0.79304, saving model to ./Model/Train_94_0.8151_0.7400_0.7838_0.7930.h5\n",
      "146/146 [==============================] - 0s 913us/sample - loss: 0.7400 - accuracy: 0.8151 - val_loss: 0.7930 - val_accuracy: 0.7838\n",
      "Epoch 95/2000\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.79304 to 0.78962, saving model to ./Model/Train_95_0.8082_0.7298_0.7838_0.7896.h5\n",
      "146/146 [==============================] - 0s 905us/sample - loss: 0.7298 - accuracy: 0.8082 - val_loss: 0.7896 - val_accuracy: 0.7838\n",
      "Epoch 96/2000\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.78962 to 0.78602, saving model to ./Model/Train_96_0.7329_0.7608_0.7568_0.7860.h5\n",
      "146/146 [==============================] - 0s 916us/sample - loss: 0.7608 - accuracy: 0.7329 - val_loss: 0.7860 - val_accuracy: 0.7568\n",
      "Epoch 97/2000\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.78602 to 0.78145, saving model to ./Model/Train_97_0.7740_0.7357_0.7568_0.7814.h5\n",
      "146/146 [==============================] - 0s 1000us/sample - loss: 0.7357 - accuracy: 0.7740 - val_loss: 0.7814 - val_accuracy: 0.7568\n",
      "Epoch 98/2000\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.78145 to 0.77634, saving model to ./Model/Train_98_0.7945_0.7134_0.7568_0.7763.h5\n",
      "146/146 [==============================] - 0s 979us/sample - loss: 0.7134 - accuracy: 0.7945 - val_loss: 0.7763 - val_accuracy: 0.7568\n",
      "Epoch 99/2000\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.77634 to 0.77091, saving model to ./Model/Train_99_0.7808_0.7343_0.7568_0.7709.h5\n",
      "146/146 [==============================] - 0s 941us/sample - loss: 0.7343 - accuracy: 0.7808 - val_loss: 0.7709 - val_accuracy: 0.7568\n",
      "Epoch 100/2000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.77091 to 0.76504, saving model to ./Model/Train_100_0.7466_0.7382_0.7838_0.7650.h5\n",
      "146/146 [==============================] - 0s 860us/sample - loss: 0.7382 - accuracy: 0.7466 - val_loss: 0.7650 - val_accuracy: 0.7838\n",
      "Epoch 101/2000\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.76504 to 0.75875, saving model to ./Model/Train_101_0.8356_0.7030_0.7838_0.7587.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.7030 - accuracy: 0.8356 - val_loss: 0.7587 - val_accuracy: 0.7838\n",
      "Epoch 102/2000\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.75875 to 0.75255, saving model to ./Model/Train_102_0.7945_0.6953_0.7568_0.7526.h5\n",
      "146/146 [==============================] - 0s 949us/sample - loss: 0.6953 - accuracy: 0.7945 - val_loss: 0.7526 - val_accuracy: 0.7568\n",
      "Epoch 103/2000\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.75255 to 0.74744, saving model to ./Model/Train_103_0.7945_0.6994_0.7568_0.7474.h5\n",
      "146/146 [==============================] - 0s 910us/sample - loss: 0.6994 - accuracy: 0.7945 - val_loss: 0.7474 - val_accuracy: 0.7568\n",
      "Epoch 104/2000\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.74744 to 0.74263, saving model to ./Model/Train_104_0.7877_0.6954_0.7568_0.7426.h5\n",
      "146/146 [==============================] - 0s 965us/sample - loss: 0.6954 - accuracy: 0.7877 - val_loss: 0.7426 - val_accuracy: 0.7568\n",
      "Epoch 105/2000\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.74263 to 0.73843, saving model to ./Model/Train_105_0.7808_0.7056_0.7568_0.7384.h5\n",
      "146/146 [==============================] - 0s 991us/sample - loss: 0.7056 - accuracy: 0.7808 - val_loss: 0.7384 - val_accuracy: 0.7568\n",
      "Epoch 106/2000\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.73843 to 0.73482, saving model to ./Model/Train_106_0.8014_0.6843_0.7568_0.7348.h5\n",
      "146/146 [==============================] - 0s 906us/sample - loss: 0.6843 - accuracy: 0.8014 - val_loss: 0.7348 - val_accuracy: 0.7568\n",
      "Epoch 107/2000\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.73482 to 0.73117, saving model to ./Model/Train_107_0.8151_0.6802_0.7568_0.7312.h5\n",
      "146/146 [==============================] - 0s 909us/sample - loss: 0.6802 - accuracy: 0.8151 - val_loss: 0.7312 - val_accuracy: 0.7568\n",
      "Epoch 108/2000\n",
      "\n",
      "Epoch 00108: val_loss improved from 0.73117 to 0.72784, saving model to ./Model/Train_108_0.8014_0.6704_0.7568_0.7278.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6704 - accuracy: 0.8014 - val_loss: 0.7278 - val_accuracy: 0.7568\n",
      "Epoch 109/2000\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.72784 to 0.72469, saving model to ./Model/Train_109_0.7808_0.6596_0.7568_0.7247.h5\n",
      "146/146 [==============================] - 0s 808us/sample - loss: 0.6596 - accuracy: 0.7808 - val_loss: 0.7247 - val_accuracy: 0.7568\n",
      "Epoch 110/2000\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.72469 to 0.72222, saving model to ./Model/Train_110_0.7877_0.6510_0.7838_0.7222.h5\n",
      "146/146 [==============================] - 0s 939us/sample - loss: 0.6510 - accuracy: 0.7877 - val_loss: 0.7222 - val_accuracy: 0.7838\n",
      "Epoch 111/2000\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.72222 to 0.71944, saving model to ./Model/Train_111_0.8014_0.6582_0.7838_0.7194.h5\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.6582 - accuracy: 0.8014 - val_loss: 0.7194 - val_accuracy: 0.7838\n",
      "Epoch 112/2000\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.71944 to 0.71654, saving model to ./Model/Train_112_0.7877_0.6554_0.7838_0.7165.h5\n",
      "146/146 [==============================] - 0s 859us/sample - loss: 0.6554 - accuracy: 0.7877 - val_loss: 0.7165 - val_accuracy: 0.7838\n",
      "Epoch 113/2000\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.71654 to 0.71356, saving model to ./Model/Train_113_0.7603_0.6508_0.7568_0.7136.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6508 - accuracy: 0.7603 - val_loss: 0.7136 - val_accuracy: 0.7568\n",
      "Epoch 114/2000\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.71356 to 0.70970, saving model to ./Model/Train_114_0.7740_0.6397_0.7838_0.7097.h5\n",
      "146/146 [==============================] - 0s 797us/sample - loss: 0.6397 - accuracy: 0.7740 - val_loss: 0.7097 - val_accuracy: 0.7838\n",
      "Epoch 115/2000\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.70970 to 0.70540, saving model to ./Model/Train_115_0.7397_0.6699_0.7568_0.7054.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6699 - accuracy: 0.7397 - val_loss: 0.7054 - val_accuracy: 0.7568\n",
      "Epoch 116/2000\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.70540 to 0.70066, saving model to ./Model/Train_116_0.7534_0.6584_0.7568_0.7007.h5\n",
      "146/146 [==============================] - 0s 851us/sample - loss: 0.6584 - accuracy: 0.7534 - val_loss: 0.7007 - val_accuracy: 0.7568\n",
      "Epoch 117/2000\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.70066 to 0.69631, saving model to ./Model/Train_117_0.7877_0.6512_0.7568_0.6963.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6512 - accuracy: 0.7877 - val_loss: 0.6963 - val_accuracy: 0.7568\n",
      "Epoch 118/2000\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.69631 to 0.69297, saving model to ./Model/Train_118_0.7466_0.6620_0.7568_0.6930.h5\n",
      "146/146 [==============================] - 0s 903us/sample - loss: 0.6620 - accuracy: 0.7466 - val_loss: 0.6930 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/2000\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.69297 to 0.69050, saving model to ./Model/Train_119_0.7808_0.6498_0.7568_0.6905.h5\n",
      "146/146 [==============================] - 0s 847us/sample - loss: 0.6498 - accuracy: 0.7808 - val_loss: 0.6905 - val_accuracy: 0.7568\n",
      "Epoch 120/2000\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.69050 to 0.68899, saving model to ./Model/Train_120_0.8014_0.6128_0.7568_0.6890.h5\n",
      "146/146 [==============================] - 0s 918us/sample - loss: 0.6128 - accuracy: 0.8014 - val_loss: 0.6890 - val_accuracy: 0.7568\n",
      "Epoch 121/2000\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.68899 to 0.68786, saving model to ./Model/Train_121_0.8014_0.6154_0.7568_0.6879.h5\n",
      "146/146 [==============================] - 0s 932us/sample - loss: 0.6154 - accuracy: 0.8014 - val_loss: 0.6879 - val_accuracy: 0.7568\n",
      "Epoch 122/2000\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.68786 to 0.68618, saving model to ./Model/Train_122_0.7671_0.6297_0.7568_0.6862.h5\n",
      "146/146 [==============================] - 0s 910us/sample - loss: 0.6297 - accuracy: 0.7671 - val_loss: 0.6862 - val_accuracy: 0.7568\n",
      "Epoch 123/2000\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.68618 to 0.68435, saving model to ./Model/Train_123_0.8151_0.6093_0.7568_0.6844.h5\n",
      "146/146 [==============================] - 0s 990us/sample - loss: 0.6093 - accuracy: 0.8151 - val_loss: 0.6844 - val_accuracy: 0.7568\n",
      "Epoch 124/2000\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.68435 to 0.68131, saving model to ./Model/Train_124_0.7671_0.6198_0.7568_0.6813.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6198 - accuracy: 0.7671 - val_loss: 0.6813 - val_accuracy: 0.7568\n",
      "Epoch 125/2000\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.68131 to 0.67757, saving model to ./Model/Train_125_0.7603_0.6182_0.7297_0.6776.h5\n",
      "146/146 [==============================] - 0s 916us/sample - loss: 0.6182 - accuracy: 0.7603 - val_loss: 0.6776 - val_accuracy: 0.7297\n",
      "Epoch 126/2000\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.67757 to 0.67336, saving model to ./Model/Train_126_0.7877_0.5850_0.7568_0.6734.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.5850 - accuracy: 0.7877 - val_loss: 0.6734 - val_accuracy: 0.7568\n",
      "Epoch 127/2000\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.67336 to 0.66922, saving model to ./Model/Train_127_0.7945_0.5947_0.7568_0.6692.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5947 - accuracy: 0.7945 - val_loss: 0.6692 - val_accuracy: 0.7568\n",
      "Epoch 128/2000\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.66922 to 0.66559, saving model to ./Model/Train_128_0.7466_0.6158_0.7568_0.6656.h5\n",
      "146/146 [==============================] - 0s 998us/sample - loss: 0.6158 - accuracy: 0.7466 - val_loss: 0.6656 - val_accuracy: 0.7568\n",
      "Epoch 129/2000\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.66559 to 0.66262, saving model to ./Model/Train_129_0.8082_0.6063_0.7568_0.6626.h5\n",
      "146/146 [==============================] - 0s 908us/sample - loss: 0.6063 - accuracy: 0.8082 - val_loss: 0.6626 - val_accuracy: 0.7568\n",
      "Epoch 130/2000\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.66262 to 0.66006, saving model to ./Model/Train_130_0.8014_0.5884_0.7568_0.6601.h5\n",
      "146/146 [==============================] - 0s 863us/sample - loss: 0.5884 - accuracy: 0.8014 - val_loss: 0.6601 - val_accuracy: 0.7568\n",
      "Epoch 131/2000\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.66006 to 0.65822, saving model to ./Model/Train_131_0.7671_0.6238_0.7568_0.6582.h5\n",
      "146/146 [==============================] - 0s 984us/sample - loss: 0.6238 - accuracy: 0.7671 - val_loss: 0.6582 - val_accuracy: 0.7568\n",
      "Epoch 132/2000\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.65822 to 0.65767, saving model to ./Model/Train_132_0.7740_0.6036_0.7568_0.6577.h5\n",
      "146/146 [==============================] - 0s 904us/sample - loss: 0.6036 - accuracy: 0.7740 - val_loss: 0.6577 - val_accuracy: 0.7568\n",
      "Epoch 133/2000\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.65767 to 0.65621, saving model to ./Model/Train_133_0.7945_0.5822_0.7568_0.6562.h5\n",
      "146/146 [==============================] - 0s 859us/sample - loss: 0.5822 - accuracy: 0.7945 - val_loss: 0.6562 - val_accuracy: 0.7568\n",
      "Epoch 134/2000\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.65621 to 0.65481, saving model to ./Model/Train_134_0.7534_0.6114_0.7568_0.6548.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.6114 - accuracy: 0.7534 - val_loss: 0.6548 - val_accuracy: 0.7568\n",
      "Epoch 135/2000\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.65481 to 0.65153, saving model to ./Model/Train_135_0.8082_0.5642_0.7568_0.6515.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.5642 - accuracy: 0.8082 - val_loss: 0.6515 - val_accuracy: 0.7568\n",
      "Epoch 136/2000\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.65153 to 0.64781, saving model to ./Model/Train_136_0.7808_0.5751_0.7568_0.6478.h5\n",
      "146/146 [==============================] - 0s 971us/sample - loss: 0.5751 - accuracy: 0.7808 - val_loss: 0.6478 - val_accuracy: 0.7568\n",
      "Epoch 137/2000\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.64781 to 0.64369, saving model to ./Model/Train_137_0.7740_0.5742_0.7568_0.6437.h5\n",
      "146/146 [==============================] - 0s 1000us/sample - loss: 0.5742 - accuracy: 0.7740 - val_loss: 0.6437 - val_accuracy: 0.7568\n",
      "Epoch 138/2000\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.64369 to 0.64046, saving model to ./Model/Train_138_0.7945_0.5770_0.7568_0.6405.h5\n",
      "146/146 [==============================] - 0s 856us/sample - loss: 0.5770 - accuracy: 0.7945 - val_loss: 0.6405 - val_accuracy: 0.7568\n",
      "Epoch 139/2000\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.64046 to 0.63832, saving model to ./Model/Train_139_0.8014_0.5692_0.7568_0.6383.h5\n",
      "146/146 [==============================] - 0s 793us/sample - loss: 0.5692 - accuracy: 0.8014 - val_loss: 0.6383 - val_accuracy: 0.7568\n",
      "Epoch 140/2000\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.63832 to 0.63562, saving model to ./Model/Train_140_0.7877_0.5754_0.7568_0.6356.h5\n",
      "146/146 [==============================] - 0s 856us/sample - loss: 0.5754 - accuracy: 0.7877 - val_loss: 0.6356 - val_accuracy: 0.7568\n",
      "Epoch 141/2000\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.63562 to 0.63373, saving model to ./Model/Train_141_0.7945_0.5651_0.7568_0.6337.h5\n",
      "146/146 [==============================] - 0s 993us/sample - loss: 0.5651 - accuracy: 0.7945 - val_loss: 0.6337 - val_accuracy: 0.7568\n",
      "Epoch 142/2000\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.63373 to 0.63223, saving model to ./Model/Train_142_0.8014_0.5653_0.7568_0.6322.h5\n",
      "146/146 [==============================] - 0s 854us/sample - loss: 0.5653 - accuracy: 0.8014 - val_loss: 0.6322 - val_accuracy: 0.7568\n",
      "Epoch 143/2000\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.63223 to 0.63128, saving model to ./Model/Train_143_0.8082_0.5577_0.7568_0.6313.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5577 - accuracy: 0.8082 - val_loss: 0.6313 - val_accuracy: 0.7568\n",
      "Epoch 144/2000\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.63128 to 0.63010, saving model to ./Model/Train_144_0.8014_0.5696_0.7568_0.6301.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.5696 - accuracy: 0.8014 - val_loss: 0.6301 - val_accuracy: 0.7568\n",
      "Epoch 145/2000\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.63010 to 0.62872, saving model to ./Model/Train_145_0.7808_0.5610_0.7568_0.6287.h5\n",
      "146/146 [==============================] - 0s 852us/sample - loss: 0.5610 - accuracy: 0.7808 - val_loss: 0.6287 - val_accuracy: 0.7568\n",
      "Epoch 146/2000\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.62872 to 0.62799, saving model to ./Model/Train_146_0.8151_0.5523_0.7568_0.6280.h5\n",
      "146/146 [==============================] - 0s 910us/sample - loss: 0.5523 - accuracy: 0.8151 - val_loss: 0.6280 - val_accuracy: 0.7568\n",
      "Epoch 147/2000\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.62799 to 0.62710, saving model to ./Model/Train_147_0.8014_0.5556_0.7568_0.6271.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5556 - accuracy: 0.8014 - val_loss: 0.6271 - val_accuracy: 0.7568\n",
      "Epoch 148/2000\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.62710 to 0.62638, saving model to ./Model/Train_148_0.8082_0.5624_0.7838_0.6264.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5624 - accuracy: 0.8082 - val_loss: 0.6264 - val_accuracy: 0.7838\n",
      "Epoch 149/2000\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.62638 to 0.62435, saving model to ./Model/Train_149_0.8082_0.5562_0.7838_0.6244.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146/146 [==============================] - 0s 796us/sample - loss: 0.5562 - accuracy: 0.8082 - val_loss: 0.6244 - val_accuracy: 0.7838\n",
      "Epoch 150/2000\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.62435 to 0.62241, saving model to ./Model/Train_150_0.7329_0.5857_0.7838_0.6224.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5857 - accuracy: 0.7329 - val_loss: 0.6224 - val_accuracy: 0.7838\n",
      "Epoch 151/2000\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.62241 to 0.62007, saving model to ./Model/Train_151_0.8151_0.5418_0.7568_0.6201.h5\n",
      "146/146 [==============================] - 0s 946us/sample - loss: 0.5418 - accuracy: 0.8151 - val_loss: 0.6201 - val_accuracy: 0.7568\n",
      "Epoch 152/2000\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.62007 to 0.61669, saving model to ./Model/Train_152_0.8014_0.5461_0.7568_0.6167.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5461 - accuracy: 0.8014 - val_loss: 0.6167 - val_accuracy: 0.7568\n",
      "Epoch 153/2000\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.61669 to 0.61349, saving model to ./Model/Train_153_0.7671_0.5390_0.7568_0.6135.h5\n",
      "146/146 [==============================] - 0s 800us/sample - loss: 0.5390 - accuracy: 0.7671 - val_loss: 0.6135 - val_accuracy: 0.7568\n",
      "Epoch 154/2000\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.61349 to 0.61094, saving model to ./Model/Train_154_0.7740_0.5395_0.7568_0.6109.h5\n",
      "146/146 [==============================] - 0s 950us/sample - loss: 0.5395 - accuracy: 0.7740 - val_loss: 0.6109 - val_accuracy: 0.7568\n",
      "Epoch 155/2000\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.61094 to 0.60867, saving model to ./Model/Train_155_0.8082_0.5240_0.7568_0.6087.h5\n",
      "146/146 [==============================] - 0s 850us/sample - loss: 0.5240 - accuracy: 0.8082 - val_loss: 0.6087 - val_accuracy: 0.7568\n",
      "Epoch 156/2000\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.60867 to 0.60660, saving model to ./Model/Train_156_0.7877_0.5503_0.7568_0.6066.h5\n",
      "146/146 [==============================] - 0s 906us/sample - loss: 0.5503 - accuracy: 0.7877 - val_loss: 0.6066 - val_accuracy: 0.7568\n",
      "Epoch 157/2000\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.60660 to 0.60462, saving model to ./Model/Train_157_0.7877_0.5410_0.7568_0.6046.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5410 - accuracy: 0.7877 - val_loss: 0.6046 - val_accuracy: 0.7568\n",
      "Epoch 158/2000\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.60462 to 0.60343, saving model to ./Model/Train_158_0.8288_0.5300_0.7568_0.6034.h5\n",
      "146/146 [==============================] - 0s 919us/sample - loss: 0.5300 - accuracy: 0.8288 - val_loss: 0.6034 - val_accuracy: 0.7568\n",
      "Epoch 159/2000\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.60343 to 0.60232, saving model to ./Model/Train_159_0.7877_0.5334_0.7568_0.6023.h5\n",
      "146/146 [==============================] - 0s 884us/sample - loss: 0.5334 - accuracy: 0.7877 - val_loss: 0.6023 - val_accuracy: 0.7568\n",
      "Epoch 160/2000\n",
      "\n",
      "Epoch 00160: val_loss improved from 0.60232 to 0.60162, saving model to ./Model/Train_160_0.7945_0.5349_0.7568_0.6016.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5349 - accuracy: 0.7945 - val_loss: 0.6016 - val_accuracy: 0.7568\n",
      "Epoch 161/2000\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.60162 to 0.60015, saving model to ./Model/Train_161_0.8082_0.5082_0.7568_0.6001.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5082 - accuracy: 0.8082 - val_loss: 0.6001 - val_accuracy: 0.7568\n",
      "Epoch 162/2000\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.60015 to 0.59818, saving model to ./Model/Train_162_0.7808_0.5256_0.7568_0.5982.h5\n",
      "146/146 [==============================] - 0s 967us/sample - loss: 0.5256 - accuracy: 0.7808 - val_loss: 0.5982 - val_accuracy: 0.7568\n",
      "Epoch 163/2000\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.59818 to 0.59664, saving model to ./Model/Train_163_0.8219_0.5242_0.7568_0.5966.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5242 - accuracy: 0.8219 - val_loss: 0.5966 - val_accuracy: 0.7568\n",
      "Epoch 164/2000\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.59664 to 0.59468, saving model to ./Model/Train_164_0.8082_0.5136_0.7568_0.5947.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5136 - accuracy: 0.8082 - val_loss: 0.5947 - val_accuracy: 0.7568\n",
      "Epoch 165/2000\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.59468 to 0.59382, saving model to ./Model/Train_165_0.8014_0.5234_0.7568_0.5938.h5\n",
      "146/146 [==============================] - 0s 948us/sample - loss: 0.5234 - accuracy: 0.8014 - val_loss: 0.5938 - val_accuracy: 0.7568\n",
      "Epoch 166/2000\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.59382 to 0.59328, saving model to ./Model/Train_166_0.7945_0.5408_0.7568_0.5933.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5408 - accuracy: 0.7945 - val_loss: 0.5933 - val_accuracy: 0.7568\n",
      "Epoch 167/2000\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.59328 to 0.59256, saving model to ./Model/Train_167_0.8219_0.4997_0.7568_0.5926.h5\n",
      "146/146 [==============================] - 0s 905us/sample - loss: 0.4997 - accuracy: 0.8219 - val_loss: 0.5926 - val_accuracy: 0.7568\n",
      "Epoch 168/2000\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.59256 to 0.59046, saving model to ./Model/Train_168_0.7740_0.5427_0.7568_0.5905.h5\n",
      "146/146 [==============================] - 0s 908us/sample - loss: 0.5427 - accuracy: 0.7740 - val_loss: 0.5905 - val_accuracy: 0.7568\n",
      "Epoch 169/2000\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.59046 to 0.58872, saving model to ./Model/Train_169_0.8014_0.5225_0.7568_0.5887.h5\n",
      "146/146 [==============================] - 0s 855us/sample - loss: 0.5225 - accuracy: 0.8014 - val_loss: 0.5887 - val_accuracy: 0.7568\n",
      "Epoch 170/2000\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.58872 to 0.58710, saving model to ./Model/Train_170_0.7534_0.5316_0.7568_0.5871.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.5316 - accuracy: 0.7534 - val_loss: 0.5871 - val_accuracy: 0.7568\n",
      "Epoch 171/2000\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.58710 to 0.58577, saving model to ./Model/Train_171_0.7877_0.5211_0.7568_0.5858.h5\n",
      "146/146 [==============================] - 0s 888us/sample - loss: 0.5211 - accuracy: 0.7877 - val_loss: 0.5858 - val_accuracy: 0.7568\n",
      "Epoch 172/2000\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.58577 to 0.58371, saving model to ./Model/Train_172_0.8219_0.5000_0.7568_0.5837.h5\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.5000 - accuracy: 0.8219 - val_loss: 0.5837 - val_accuracy: 0.7568\n",
      "Epoch 173/2000\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.58371 to 0.58316, saving model to ./Model/Train_173_0.7877_0.5474_0.7568_0.5832.h5\n",
      "146/146 [==============================] - 0s 789us/sample - loss: 0.5474 - accuracy: 0.7877 - val_loss: 0.5832 - val_accuracy: 0.7568\n",
      "Epoch 174/2000\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.58316 to 0.58240, saving model to ./Model/Train_174_0.8219_0.4980_0.7568_0.5824.h5\n",
      "146/146 [==============================] - 0s 741us/sample - loss: 0.4980 - accuracy: 0.8219 - val_loss: 0.5824 - val_accuracy: 0.7568\n",
      "Epoch 175/2000\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.58240 to 0.58200, saving model to ./Model/Train_175_0.7945_0.5233_0.7568_0.5820.h5\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.5233 - accuracy: 0.7945 - val_loss: 0.5820 - val_accuracy: 0.7568\n",
      "Epoch 176/2000\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.58200 to 0.58151, saving model to ./Model/Train_176_0.7945_0.5148_0.7568_0.5815.h5\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 0.5148 - accuracy: 0.7945 - val_loss: 0.5815 - val_accuracy: 0.7568\n",
      "Epoch 177/2000\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.58151 to 0.57980, saving model to ./Model/Train_177_0.7877_0.5125_0.7568_0.5798.h5\n",
      "146/146 [==============================] - 0s 743us/sample - loss: 0.5125 - accuracy: 0.7877 - val_loss: 0.5798 - val_accuracy: 0.7568\n",
      "Epoch 178/2000\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.57980 to 0.57841, saving model to ./Model/Train_178_0.8151_0.4913_0.7568_0.5784.h5\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.4913 - accuracy: 0.8151 - val_loss: 0.5784 - val_accuracy: 0.7568\n",
      "Epoch 179/2000\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.57841 to 0.57721, saving model to ./Model/Train_179_0.7877_0.5115_0.7568_0.5772.h5\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.5115 - accuracy: 0.7877 - val_loss: 0.5772 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/2000\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.57721 to 0.57621, saving model to ./Model/Train_180_0.8014_0.5184_0.7568_0.5762.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5184 - accuracy: 0.8014 - val_loss: 0.5762 - val_accuracy: 0.7568\n",
      "Epoch 181/2000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.57621\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5314 - accuracy: 0.7877 - val_loss: 0.5763 - val_accuracy: 0.7568\n",
      "Epoch 182/2000\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.57621\n",
      "146/146 [==============================] - 0s 769us/sample - loss: 0.5187 - accuracy: 0.7808 - val_loss: 0.5771 - val_accuracy: 0.7568\n",
      "Epoch 183/2000\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.57621\n",
      "146/146 [==============================] - 0s 671us/sample - loss: 0.5081 - accuracy: 0.7945 - val_loss: 0.5774 - val_accuracy: 0.7568\n",
      "Epoch 184/2000\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.57621\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.5119 - accuracy: 0.7877 - val_loss: 0.5770 - val_accuracy: 0.7838\n",
      "Epoch 185/2000\n",
      "\n",
      "Epoch 00185: val_loss improved from 0.57621 to 0.57584, saving model to ./Model/Train_185_0.7945_0.5172_0.7838_0.5758.h5\n",
      "146/146 [==============================] - 0s 862us/sample - loss: 0.5172 - accuracy: 0.7945 - val_loss: 0.5758 - val_accuracy: 0.7838\n",
      "Epoch 186/2000\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.57584 to 0.57386, saving model to ./Model/Train_186_0.8014_0.5034_0.7838_0.5739.h5\n",
      "146/146 [==============================] - 0s 895us/sample - loss: 0.5034 - accuracy: 0.8014 - val_loss: 0.5739 - val_accuracy: 0.7838\n",
      "Epoch 187/2000\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.57386 to 0.57198, saving model to ./Model/Train_187_0.7740_0.5139_0.7568_0.5720.h5\n",
      "146/146 [==============================] - 0s 951us/sample - loss: 0.5139 - accuracy: 0.7740 - val_loss: 0.5720 - val_accuracy: 0.7568\n",
      "Epoch 188/2000\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.57198 to 0.56978, saving model to ./Model/Train_188_0.7740_0.5143_0.7568_0.5698.h5\n",
      "146/146 [==============================] - 0s 961us/sample - loss: 0.5143 - accuracy: 0.7740 - val_loss: 0.5698 - val_accuracy: 0.7568\n",
      "Epoch 189/2000\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.56978 to 0.56776, saving model to ./Model/Train_189_0.7877_0.5185_0.7568_0.5678.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5185 - accuracy: 0.7877 - val_loss: 0.5678 - val_accuracy: 0.7568\n",
      "Epoch 190/2000\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.56776 to 0.56594, saving model to ./Model/Train_190_0.8288_0.4856_0.7568_0.5659.h5\n",
      "146/146 [==============================] - 0s 993us/sample - loss: 0.4856 - accuracy: 0.8288 - val_loss: 0.5659 - val_accuracy: 0.7568\n",
      "Epoch 191/2000\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.56594 to 0.56447, saving model to ./Model/Train_191_0.8014_0.4876_0.7568_0.5645.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4876 - accuracy: 0.8014 - val_loss: 0.5645 - val_accuracy: 0.7568\n",
      "Epoch 192/2000\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.56447 to 0.56432, saving model to ./Model/Train_192_0.7740_0.5109_0.7568_0.5643.h5\n",
      "146/146 [==============================] - 0s 906us/sample - loss: 0.5109 - accuracy: 0.7740 - val_loss: 0.5643 - val_accuracy: 0.7568\n",
      "Epoch 193/2000\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 675us/sample - loss: 0.4963 - accuracy: 0.8014 - val_loss: 0.5645 - val_accuracy: 0.7568\n",
      "Epoch 194/2000\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.5018 - accuracy: 0.7877 - val_loss: 0.5651 - val_accuracy: 0.7568\n",
      "Epoch 195/2000\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.5015 - accuracy: 0.7740 - val_loss: 0.5667 - val_accuracy: 0.7838\n",
      "Epoch 196/2000\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5139 - accuracy: 0.7740 - val_loss: 0.5674 - val_accuracy: 0.7838\n",
      "Epoch 197/2000\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.56432\n",
      "\n",
      "Epoch 00197: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "146/146 [==============================] - 0s 916us/sample - loss: 0.4917 - accuracy: 0.8219 - val_loss: 0.5679 - val_accuracy: 0.7838\n",
      "Epoch 198/2000\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 735us/sample - loss: 0.5206 - accuracy: 0.8014 - val_loss: 0.5683 - val_accuracy: 0.7838\n",
      "Epoch 199/2000\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4861 - accuracy: 0.7740 - val_loss: 0.5683 - val_accuracy: 0.7838\n",
      "Epoch 200/2000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.5014 - accuracy: 0.8014 - val_loss: 0.5671 - val_accuracy: 0.7838\n",
      "Epoch 201/2000\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.56432\n",
      "146/146 [==============================] - 0s 677us/sample - loss: 0.4893 - accuracy: 0.8082 - val_loss: 0.5663 - val_accuracy: 0.7838\n",
      "Epoch 202/2000\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.56432\n",
      "\n",
      "Epoch 00202: ReduceLROnPlateau reducing learning rate to 0.0008100000384729356.\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4901 - accuracy: 0.7945 - val_loss: 0.5647 - val_accuracy: 0.7838\n",
      "Epoch 203/2000\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.56432 to 0.56407, saving model to ./Model/Train_203_0.7740_0.5006_0.7568_0.5641.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.5006 - accuracy: 0.7740 - val_loss: 0.5641 - val_accuracy: 0.7568\n",
      "Epoch 204/2000\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.56407 to 0.56348, saving model to ./Model/Train_204_0.8288_0.4611_0.7568_0.5635.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4611 - accuracy: 0.8288 - val_loss: 0.5635 - val_accuracy: 0.7568\n",
      "Epoch 205/2000\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.56348 to 0.56322, saving model to ./Model/Train_205_0.8219_0.4882_0.7568_0.5632.h5\n",
      "146/146 [==============================] - 0s 794us/sample - loss: 0.4882 - accuracy: 0.8219 - val_loss: 0.5632 - val_accuracy: 0.7568\n",
      "Epoch 206/2000\n",
      "\n",
      "Epoch 00206: val_loss improved from 0.56322 to 0.56215, saving model to ./Model/Train_206_0.7945_0.5034_0.7568_0.5621.h5\n",
      "146/146 [==============================] - 0s 909us/sample - loss: 0.5034 - accuracy: 0.7945 - val_loss: 0.5621 - val_accuracy: 0.7568\n",
      "Epoch 207/2000\n",
      "\n",
      "Epoch 00207: val_loss improved from 0.56215 to 0.56104, saving model to ./Model/Train_207_0.7808_0.4843_0.7568_0.5610.h5\n",
      "146/146 [==============================] - 0s 738us/sample - loss: 0.4843 - accuracy: 0.7808 - val_loss: 0.5610 - val_accuracy: 0.7568\n",
      "Epoch 208/2000\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.56104 to 0.55995, saving model to ./Model/Train_208_0.8014_0.4822_0.7568_0.5599.h5\n",
      "146/146 [==============================] - 0s 837us/sample - loss: 0.4822 - accuracy: 0.8014 - val_loss: 0.5599 - val_accuracy: 0.7568\n",
      "Epoch 209/2000\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.55995 to 0.55981, saving model to ./Model/Train_209_0.7808_0.4906_0.7568_0.5598.h5\n",
      "146/146 [==============================] - 0s 726us/sample - loss: 0.4906 - accuracy: 0.7808 - val_loss: 0.5598 - val_accuracy: 0.7568\n",
      "Epoch 210/2000\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.55981 to 0.55971, saving model to ./Model/Train_210_0.8219_0.4857_0.7568_0.5597.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4857 - accuracy: 0.8219 - val_loss: 0.5597 - val_accuracy: 0.7568\n",
      "Epoch 211/2000\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.55971 to 0.55963, saving model to ./Model/Train_211_0.7877_0.4898_0.7568_0.5596.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4898 - accuracy: 0.7877 - val_loss: 0.5596 - val_accuracy: 0.7568\n",
      "Epoch 212/2000\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.4639 - accuracy: 0.8014 - val_loss: 0.5598 - val_accuracy: 0.7568\n",
      "Epoch 213/2000\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.4829 - accuracy: 0.7671 - val_loss: 0.5601 - val_accuracy: 0.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/2000\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 772us/sample - loss: 0.5007 - accuracy: 0.7945 - val_loss: 0.5606 - val_accuracy: 0.7568\n",
      "Epoch 215/2000\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.4558 - accuracy: 0.8082 - val_loss: 0.5605 - val_accuracy: 0.7568\n",
      "Epoch 216/2000\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.55963\n",
      "\n",
      "Epoch 00216: ReduceLROnPlateau reducing learning rate to 0.0007290000503417104.\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.4817 - accuracy: 0.8356 - val_loss: 0.5607 - val_accuracy: 0.7838\n",
      "Epoch 217/2000\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4753 - accuracy: 0.8219 - val_loss: 0.5603 - val_accuracy: 0.7838\n",
      "Epoch 218/2000\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.55963\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.4640 - accuracy: 0.8288 - val_loss: 0.5600 - val_accuracy: 0.7838\n",
      "Epoch 219/2000\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.55963 to 0.55863, saving model to ./Model/Train_219_0.7808_0.4808_0.7568_0.5586.h5\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.4808 - accuracy: 0.7808 - val_loss: 0.5586 - val_accuracy: 0.7568\n",
      "Epoch 220/2000\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.55863 to 0.55671, saving model to ./Model/Train_220_0.7945_0.4898_0.7568_0.5567.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4898 - accuracy: 0.7945 - val_loss: 0.5567 - val_accuracy: 0.7568\n",
      "Epoch 221/2000\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.55671 to 0.55502, saving model to ./Model/Train_221_0.8082_0.4618_0.7568_0.5550.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4618 - accuracy: 0.8082 - val_loss: 0.5550 - val_accuracy: 0.7568\n",
      "Epoch 222/2000\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.55502 to 0.55332, saving model to ./Model/Train_222_0.7808_0.4718_0.7568_0.5533.h5\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.4718 - accuracy: 0.7808 - val_loss: 0.5533 - val_accuracy: 0.7568\n",
      "Epoch 223/2000\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.55332 to 0.55221, saving model to ./Model/Train_223_0.8219_0.4763_0.7568_0.5522.h5\n",
      "146/146 [==============================] - 0s 919us/sample - loss: 0.4763 - accuracy: 0.8219 - val_loss: 0.5522 - val_accuracy: 0.7568\n",
      "Epoch 224/2000\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.55221 to 0.55181, saving model to ./Model/Train_224_0.8151_0.4647_0.7568_0.5518.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4647 - accuracy: 0.8151 - val_loss: 0.5518 - val_accuracy: 0.7568\n",
      "Epoch 225/2000\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.55181 to 0.55173, saving model to ./Model/Train_225_0.8219_0.4595_0.7568_0.5517.h5\n",
      "146/146 [==============================] - 0s 884us/sample - loss: 0.4595 - accuracy: 0.8219 - val_loss: 0.5517 - val_accuracy: 0.7568\n",
      "Epoch 226/2000\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 774us/sample - loss: 0.4528 - accuracy: 0.8288 - val_loss: 0.5524 - val_accuracy: 0.7568\n",
      "Epoch 227/2000\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 964us/sample - loss: 0.4551 - accuracy: 0.8356 - val_loss: 0.5540 - val_accuracy: 0.7568\n",
      "Epoch 228/2000\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 678us/sample - loss: 0.4739 - accuracy: 0.8082 - val_loss: 0.5553 - val_accuracy: 0.7568\n",
      "Epoch 229/2000\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.55173\n",
      "\n",
      "Epoch 00229: ReduceLROnPlateau reducing learning rate to 0.0006561000715009868.\n",
      "146/146 [==============================] - 0s 699us/sample - loss: 0.4768 - accuracy: 0.7945 - val_loss: 0.5565 - val_accuracy: 0.7568\n",
      "Epoch 230/2000\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 833us/sample - loss: 0.4505 - accuracy: 0.8219 - val_loss: 0.5571 - val_accuracy: 0.7838\n",
      "Epoch 231/2000\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4725 - accuracy: 0.8219 - val_loss: 0.5571 - val_accuracy: 0.7838\n",
      "Epoch 232/2000\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.4783 - accuracy: 0.8082 - val_loss: 0.5552 - val_accuracy: 0.7568\n",
      "Epoch 233/2000\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.55173\n",
      "146/146 [==============================] - 0s 673us/sample - loss: 0.4893 - accuracy: 0.7603 - val_loss: 0.5520 - val_accuracy: 0.7568\n",
      "Epoch 234/2000\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.55173 to 0.55029, saving model to ./Model/Train_234_0.8219_0.4763_0.7568_0.5503.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4763 - accuracy: 0.8219 - val_loss: 0.5503 - val_accuracy: 0.7568\n",
      "Epoch 235/2000\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.55029 to 0.54920, saving model to ./Model/Train_235_0.8151_0.4816_0.7568_0.5492.h5\n",
      "146/146 [==============================] - 0s 791us/sample - loss: 0.4816 - accuracy: 0.8151 - val_loss: 0.5492 - val_accuracy: 0.7568\n",
      "Epoch 236/2000\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.54920 to 0.54798, saving model to ./Model/Train_236_0.8288_0.4543_0.7568_0.5480.h5\n",
      "146/146 [==============================] - 0s 912us/sample - loss: 0.4543 - accuracy: 0.8288 - val_loss: 0.5480 - val_accuracy: 0.7568\n",
      "Epoch 237/2000\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.54798 to 0.54670, saving model to ./Model/Train_237_0.8082_0.5050_0.7568_0.5467.h5\n",
      "146/146 [==============================] - 0s 806us/sample - loss: 0.5050 - accuracy: 0.8082 - val_loss: 0.5467 - val_accuracy: 0.7568\n",
      "Epoch 238/2000\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.54670 to 0.54635, saving model to ./Model/Train_238_0.8151_0.4694_0.7568_0.5464.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4694 - accuracy: 0.8151 - val_loss: 0.5464 - val_accuracy: 0.7568\n",
      "Epoch 239/2000\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.54635 to 0.54617, saving model to ./Model/Train_239_0.8082_0.4678_0.7568_0.5462.h5\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 0.4678 - accuracy: 0.8082 - val_loss: 0.5462 - val_accuracy: 0.7568\n",
      "Epoch 240/2000\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 674us/sample - loss: 0.4374 - accuracy: 0.8082 - val_loss: 0.5466 - val_accuracy: 0.7568\n",
      "Epoch 241/2000\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4615 - accuracy: 0.8151 - val_loss: 0.5475 - val_accuracy: 0.7568\n",
      "Epoch 242/2000\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.4689 - accuracy: 0.8082 - val_loss: 0.5487 - val_accuracy: 0.7838\n",
      "Epoch 243/2000\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 682us/sample - loss: 0.4441 - accuracy: 0.8493 - val_loss: 0.5496 - val_accuracy: 0.7838\n",
      "Epoch 244/2000\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.54617\n",
      "\n",
      "Epoch 00244: ReduceLROnPlateau reducing learning rate to 0.0005904900433961303.\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4782 - accuracy: 0.8219 - val_loss: 0.5499 - val_accuracy: 0.7838\n",
      "Epoch 245/2000\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 680us/sample - loss: 0.4578 - accuracy: 0.8082 - val_loss: 0.5499 - val_accuracy: 0.7838\n",
      "Epoch 246/2000\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 681us/sample - loss: 0.4485 - accuracy: 0.8562 - val_loss: 0.5493 - val_accuracy: 0.7838\n",
      "Epoch 247/2000\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4971 - accuracy: 0.7740 - val_loss: 0.5489 - val_accuracy: 0.7838\n",
      "Epoch 248/2000\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.54617\n",
      "146/146 [==============================] - 0s 685us/sample - loss: 0.4312 - accuracy: 0.8288 - val_loss: 0.5482 - val_accuracy: 0.7838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/2000\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.54617\n",
      "\n",
      "Epoch 00249: ReduceLROnPlateau reducing learning rate to 0.0005314410547725857.\n",
      "146/146 [==============================] - 0s 691us/sample - loss: 0.4656 - accuracy: 0.8288 - val_loss: 0.5473 - val_accuracy: 0.7838\n",
      "Epoch 250/2000\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.54617 to 0.54601, saving model to ./Model/Train_250_0.8219_0.4536_0.7838_0.5460.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4536 - accuracy: 0.8219 - val_loss: 0.5460 - val_accuracy: 0.7838\n",
      "Epoch 251/2000\n",
      "\n",
      "Epoch 00251: val_loss improved from 0.54601 to 0.54427, saving model to ./Model/Train_251_0.8014_0.4497_0.7838_0.5443.h5\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.4497 - accuracy: 0.8014 - val_loss: 0.5443 - val_accuracy: 0.7838\n",
      "Epoch 252/2000\n",
      "\n",
      "Epoch 00252: val_loss improved from 0.54427 to 0.54235, saving model to ./Model/Train_252_0.8014_0.4810_0.7568_0.5423.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4810 - accuracy: 0.8014 - val_loss: 0.5423 - val_accuracy: 0.7568\n",
      "Epoch 253/2000\n",
      "\n",
      "Epoch 00253: val_loss improved from 0.54235 to 0.54118, saving model to ./Model/Train_253_0.8151_0.4642_0.7568_0.5412.h5\n",
      "146/146 [==============================] - 0s 751us/sample - loss: 0.4642 - accuracy: 0.8151 - val_loss: 0.5412 - val_accuracy: 0.7568\n",
      "Epoch 254/2000\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.54118 to 0.54094, saving model to ./Model/Train_254_0.7945_0.4629_0.7568_0.5409.h5\n",
      "146/146 [==============================] - 0s 787us/sample - loss: 0.4629 - accuracy: 0.7945 - val_loss: 0.5409 - val_accuracy: 0.7568\n",
      "Epoch 255/2000\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.54094\n",
      "146/146 [==============================] - 0s 686us/sample - loss: 0.4475 - accuracy: 0.8219 - val_loss: 0.5410 - val_accuracy: 0.7568\n",
      "Epoch 256/2000\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.54094\n",
      "146/146 [==============================] - 0s 727us/sample - loss: 0.4821 - accuracy: 0.8219 - val_loss: 0.5412 - val_accuracy: 0.7838\n",
      "Epoch 257/2000\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.54094\n",
      "146/146 [==============================] - 0s 734us/sample - loss: 0.4427 - accuracy: 0.8014 - val_loss: 0.5411 - val_accuracy: 0.7838\n",
      "Epoch 258/2000\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.54094\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.4520 - accuracy: 0.7945 - val_loss: 0.5410 - val_accuracy: 0.7838\n",
      "Epoch 259/2000\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.54094\n",
      "\n",
      "Epoch 00259: ReduceLROnPlateau reducing learning rate to 0.00047829695977270604.\n",
      "146/146 [==============================] - 0s 684us/sample - loss: 0.4450 - accuracy: 0.8082 - val_loss: 0.5410 - val_accuracy: 0.7838\n",
      "Epoch 260/2000\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.54094 to 0.54057, saving model to ./Model/Train_260_0.8014_0.4657_0.7838_0.5406.h5\n",
      "146/146 [==============================] - 0s 730us/sample - loss: 0.4657 - accuracy: 0.8014 - val_loss: 0.5406 - val_accuracy: 0.7838\n",
      "Epoch 261/2000\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.54057 to 0.53982, saving model to ./Model/Train_261_0.8219_0.4400_0.7838_0.5398.h5\n",
      "146/146 [==============================] - 0s 731us/sample - loss: 0.4400 - accuracy: 0.8219 - val_loss: 0.5398 - val_accuracy: 0.7838\n",
      "Epoch 262/2000\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.53982 to 0.53940, saving model to ./Model/Train_262_0.7877_0.4689_0.7838_0.5394.h5\n",
      "146/146 [==============================] - 0s 733us/sample - loss: 0.4689 - accuracy: 0.7877 - val_loss: 0.5394 - val_accuracy: 0.7838\n",
      "Epoch 263/2000\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.53940 to 0.53887, saving model to ./Model/Train_263_0.8151_0.4503_0.7838_0.5389.h5\n",
      "146/146 [==============================] - 0s 739us/sample - loss: 0.4503 - accuracy: 0.8151 - val_loss: 0.5389 - val_accuracy: 0.7838\n",
      "Epoch 264/2000\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.53887 to 0.53845, saving model to ./Model/Train_264_0.8082_0.4587_0.7568_0.5385.h5\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4587 - accuracy: 0.8082 - val_loss: 0.5385 - val_accuracy: 0.7568\n",
      "Epoch 265/2000\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.53845 to 0.53842, saving model to ./Model/Train_265_0.8082_0.4583_0.7568_0.5384.h5\n",
      "146/146 [==============================] - 0s 887us/sample - loss: 0.4583 - accuracy: 0.8082 - val_loss: 0.5384 - val_accuracy: 0.7568\n",
      "Epoch 266/2000\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.53842 to 0.53806, saving model to ./Model/Train_266_0.8151_0.4545_0.7568_0.5381.h5\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.4545 - accuracy: 0.8151 - val_loss: 0.5381 - val_accuracy: 0.7568\n",
      "Epoch 267/2000\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.53806 to 0.53745, saving model to ./Model/Train_267_0.8082_0.4648_0.7568_0.5374.h5\n",
      "146/146 [==============================] - 0s 736us/sample - loss: 0.4648 - accuracy: 0.8082 - val_loss: 0.5374 - val_accuracy: 0.7568\n",
      "Epoch 268/2000\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.53745 to 0.53716, saving model to ./Model/Train_268_0.7945_0.4771_0.7568_0.5372.h5\n",
      "146/146 [==============================] - 0s 792us/sample - loss: 0.4771 - accuracy: 0.7945 - val_loss: 0.5372 - val_accuracy: 0.7568\n",
      "Epoch 269/2000\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.53716 to 0.53700, saving model to ./Model/Train_269_0.8288_0.4570_0.7568_0.5370.h5\n",
      "146/146 [==============================] - 0s 788us/sample - loss: 0.4570 - accuracy: 0.8288 - val_loss: 0.5370 - val_accuracy: 0.7568\n",
      "Epoch 270/2000\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.4368 - accuracy: 0.8288 - val_loss: 0.5373 - val_accuracy: 0.7568\n",
      "Epoch 271/2000\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.4779 - accuracy: 0.7945 - val_loss: 0.5382 - val_accuracy: 0.7568\n",
      "Epoch 272/2000\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.4450 - accuracy: 0.8219 - val_loss: 0.5395 - val_accuracy: 0.7568\n",
      "Epoch 273/2000\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 679us/sample - loss: 0.4561 - accuracy: 0.8014 - val_loss: 0.5410 - val_accuracy: 0.7838\n",
      "Epoch 274/2000\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.53700\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 0.0004304672533180565.\n",
      "146/146 [==============================] - 0s 705us/sample - loss: 0.4685 - accuracy: 0.7808 - val_loss: 0.5421 - val_accuracy: 0.7838\n",
      "Epoch 275/2000\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4603 - accuracy: 0.7877 - val_loss: 0.5436 - val_accuracy: 0.7838\n",
      "Epoch 276/2000\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 2ms/sample - loss: 0.4521 - accuracy: 0.8082 - val_loss: 0.5448 - val_accuracy: 0.7838\n",
      "Epoch 277/2000\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 758us/sample - loss: 0.4706 - accuracy: 0.8014 - val_loss: 0.5462 - val_accuracy: 0.7838\n",
      "Epoch 278/2000\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 676us/sample - loss: 0.4514 - accuracy: 0.7877 - val_loss: 0.5472 - val_accuracy: 0.7838\n",
      "Epoch 279/2000\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.53700\n",
      "\n",
      "Epoch 00279: ReduceLROnPlateau reducing learning rate to 0.00038742052274756136.\n",
      "146/146 [==============================] - 0s 690us/sample - loss: 0.4344 - accuracy: 0.8356 - val_loss: 0.5478 - val_accuracy: 0.7838\n",
      "Epoch 280/2000\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 717us/sample - loss: 0.4692 - accuracy: 0.7877 - val_loss: 0.5476 - val_accuracy: 0.7838\n",
      "Epoch 281/2000\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 683us/sample - loss: 0.4435 - accuracy: 0.7740 - val_loss: 0.5472 - val_accuracy: 0.7838\n",
      "Epoch 282/2000\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 1ms/sample - loss: 0.4430 - accuracy: 0.8356 - val_loss: 0.5461 - val_accuracy: 0.7838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/2000\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.53700\n",
      "146/146 [==============================] - 0s 693us/sample - loss: 0.4551 - accuracy: 0.8014 - val_loss: 0.5446 - val_accuracy: 0.7838\n",
      "Epoch 284/2000\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.53700\n",
      "\n",
      "Epoch 00284: ReduceLROnPlateau reducing learning rate to 0.0003486784757114947.\n",
      "146/146 [==============================] - 0s 773us/sample - loss: 0.4438 - accuracy: 0.8356 - val_loss: 0.5430 - val_accuracy: 0.7838\n",
      "Epoch 00284: early stopping\n"
     ]
    }
   ],
   "source": [
    "def buildModel(width, num_classes):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_dim = width))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation = 'sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss = binary_crossentropy,\n",
    "            optimizer = Adam(lr = 0.001),\n",
    "            metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def saveTrainModels(model, saveModelPath, saveTensorBoardPath, epochs, batch_size,\n",
    "                    x_train, y_train, x_val, y_val):\n",
    "    \n",
    "#     設置TensorBoard\n",
    "    tbCallBack = TensorBoard(log_dir = saveTensorBoardPath, write_images = True,\n",
    "                            embeddings_freq = 0, embeddings_layer_names = None, embeddings_metadata = None)\n",
    "    \n",
    "#     Revicing the bug of TensorBoard of TF2\n",
    "    tfPath01 = saveTensorBoardPath + '/train'\n",
    "    tfPath02 = saveTensorBoardPath + '/train/plugins'\n",
    "    tfPath03 = saveTensorBoardPath + '/train/plugins/profile'\n",
    "    if not os.path.exists(tfPath01):\n",
    "        os.mkdir(tfPath01)\n",
    "    if not os.path.exists(tfPath02):\n",
    "        os.mkdir(tfPath02)\n",
    "    if not os.path.exists(tfPath03):\n",
    "        os.mkdir(tfPath03)\n",
    "\n",
    "#     設置checkpoint\n",
    "    checkpoint = ModelCheckpoint(\n",
    "                            monitor = 'val_loss', verbose = 1, \n",
    "                            save_best_only = True, mode = 'min',\n",
    "                            filepath = ('%s_{epoch:02d}_{accuracy:.4f}_{loss:.4f}_{val_accuracy:.4f}_{val_loss:.4f}.h5' %(saveModelPath)))\n",
    "\n",
    "#     設置ReduceLROnPlateau\n",
    "    Reduce = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.9, patience = 5, cooldown = 1, verbose = 1)\n",
    "\n",
    "#     設置EarlyStopping\n",
    "    Early = EarlyStopping(monitor = 'val_loss', patience = 15, verbose = 1)\n",
    "\n",
    "    callbacks_list = [checkpoint, tbCallBack, Reduce, Early]\n",
    "\n",
    "#     訓練模型\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size = batch_size,\n",
    "                epochs = epochs,\n",
    "                verbose = 1,\n",
    "                shuffle = True,\n",
    "                validation_data = (x_val, y_val),\n",
    "                callbacks = callbacks_list)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    DataSplitRatio = 0.8\n",
    "    NumClasses = 1\n",
    "    Epochs = 2000\n",
    "    BatchSize = 512 \n",
    "    SaveModelPath = \"./Model/Train\"\n",
    "    SaveTensorBoardPath = \"./Model/Tensorboard\"\n",
    "      \n",
    "    if not os.path.exists(\"./Model\"):\n",
    "        os.mkdir(\"./Model\")\n",
    "    if not os.path.exists(SaveTensorBoardPath):\n",
    "        os.mkdir(SaveTensorBoardPath)\n",
    "    \n",
    "#     讀取資料\n",
    "    readPath = './Data/new_train.csv'\n",
    "    data = pd.read_csv(readPath)\n",
    "    data = data.drop(columns=['PassengerId'])\n",
    "    x_train = data.drop(columns=['Survived']).values\n",
    "    y_train = data['Survived'].values\n",
    "    Width = x_train.shape[1]\n",
    "    \n",
    "#     順序隨機\n",
    "    num_example = x_train.shape[0]\n",
    "    arr = np.arange(num_example)\n",
    "    np.random.shuffle(arr)\n",
    "    x_train = x_train[arr]\n",
    "    y_train = y_train[arr]\n",
    "    \n",
    "#     切割資料\n",
    "    s = np.int(num_example * DataSplitRatio)\n",
    "    x_val = x_train[s:]\n",
    "    y_val = y_train[s:]\n",
    "    x_train = x_train[:s]\n",
    "    y_train = y_train[:s]\n",
    "    \n",
    "#     Print資料量\n",
    "    print('x_train：', x_train.shape)\n",
    "    print('y_train：', y_train.shape)\n",
    "    print('x_val：', x_val.shape)\n",
    "    print('y_val：', y_val.shape)\n",
    "    \n",
    "#     建構模型\n",
    "    Model = buildModel(Width, NumClasses)\n",
    "        \n",
    "#     訓練及儲存模型\n",
    "    saveTrainModels(Model, SaveModelPath, SaveTensorBoardPath, Epochs, BatchSize, x_train, y_train, x_val, y_val)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test： (418, 8)\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Complate.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "if __name__ == \"__main__\":\n",
    "#     ModelPath = \"./Model_WithoutSelection/Train_182_0.8288_0.5042_0.7838_0.6408.h5\"\n",
    "    ModelPath = \"./Model_WithSelection/Train_269_0.8288_0.4570_0.7568_0.5370.h5\"\n",
    "    readPath = './Data/new_test.csv'\n",
    "    WritePath = \"./gender_submission.csv\"\n",
    "    \n",
    "#     讀取資料\n",
    "    data = pd.read_csv(readPath)\n",
    "    data2 = data['PassengerId']\n",
    "    data = data.drop(columns=['PassengerId'])\n",
    "    print('x_test：', data.shape)\n",
    "    \n",
    "#     載入模型\n",
    "    Model = load_model(ModelPath)\n",
    "    \n",
    "#     預測模型\n",
    "    pred = Model.predict(data)\n",
    "#     print(pred)\n",
    "    \n",
    "#     輸出結果\n",
    "    fw = open(WritePath, \"w\")\n",
    "    fw.write('PassengerId,Survived\\n')\n",
    "    for idx in range(0, pred.shape[0], 1):\n",
    "        Temp = 1 if pred[idx] > 0.5 else 0\n",
    "        fw.write('%s,%s\\n'%(data2[idx], Temp))\n",
    "    fw.close()\n",
    "    print('Complate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train： (146, 8)\n",
      "y_train： (146,)\n",
      "x_val： (37, 8)\n",
      "y_val： (37,)\n",
      "0.9178082191780822\n",
      "0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import pickle\n",
    "import os\n",
    "if __name__ == \"__main__\":\n",
    "    DataSplitRatio = 0.8\n",
    "    num_tree = 50\n",
    "    SaveModelPath = \"./Model/RFModel.pickle\"\n",
    "      \n",
    "    if not os.path.exists(\"./Model\"):\n",
    "        os.mkdir(\"./Model\")\n",
    "    \n",
    "#     讀取資料\n",
    "    readPath = './Data/new_train.csv'\n",
    "    data = pd.read_csv(readPath)\n",
    "    data = data.drop(columns=['PassengerId'])\n",
    "    x_train = data.drop(columns=['Survived']).values\n",
    "    y_train = data['Survived'].values\n",
    "    Width = x_train.shape[1]\n",
    "    \n",
    "#     順序隨機\n",
    "    num_example = x_train.shape[0]\n",
    "    arr = np.arange(num_example)\n",
    "    np.random.shuffle(arr)\n",
    "    x_train = x_train[arr]\n",
    "    y_train = y_train[arr]\n",
    "    \n",
    "#     切割資料\n",
    "    s = np.int(num_example * DataSplitRatio)\n",
    "    x_val = x_train[s:]\n",
    "    y_val = y_train[s:]\n",
    "    x_train = x_train[:s]\n",
    "    y_train = y_train[:s]\n",
    "    \n",
    "#     Print資料量\n",
    "    print('x_train：', x_train.shape)\n",
    "    print('y_train：', y_train.shape)\n",
    "    print('x_val：', x_val.shape)\n",
    "    print('y_val：', y_val.shape)\n",
    "    \n",
    "#     建構模型\n",
    "    RFModel = RandomForestClassifier(n_estimators=num_tree)\n",
    "#     RFModel = DecisionTreeClassifier()\n",
    "#     RFModel = XGBClassifier(n_estimators=num_tree)\n",
    "        \n",
    "#     訓練及儲存模型\n",
    "    RFModel.fit(x_train, y_train)\n",
    "    y_train_pred = RFModel.predict(x_train)\n",
    "    y_val_pred = RFModel.predict(x_val)\n",
    "    print(accuracy_score(y_train_pred, y_train))\n",
    "    print(accuracy_score(y_val_pred, y_val))\n",
    "    with open(SaveModelPath, 'wb') as f:\n",
    "        pickle.dump(RFModel, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest預測模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test： (418, 8)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ModelPath = \"./Model_RF/RFModel.pickle\"\n",
    "    WritePath = \"./gender_submission.csv\"\n",
    "    \n",
    "#     讀取資料\n",
    "    readPath = './Data/new_test.csv'\n",
    "    data = pd.read_csv(readPath)\n",
    "    data2 = data['PassengerId']\n",
    "    data = data.drop(columns=['PassengerId'])\n",
    "    print('x_test：', data.shape)\n",
    "    \n",
    "    data.columns = ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7']\n",
    "#     data.columns = ['f0', 'f1', 'f2', 'f3']\n",
    "    \n",
    "#     載入模型\n",
    "    with open(ModelPath, 'rb') as f:\n",
    "        RFModel = pickle.load(f)\n",
    "    \n",
    "#     預測模型\n",
    "    pred = RFModel.predict(data)\n",
    "#     print(pred)\n",
    "    \n",
    "#     輸出結果\n",
    "    fw = open(WritePath, \"w\")\n",
    "    fw.write('PassengerId,Survived\\n')\n",
    "    for idx in range(0, pred.shape[0], 1):\n",
    "        fw.write('%s,%d\\n'%(data2[idx], int(pred[idx])))\n",
    "    fw.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
